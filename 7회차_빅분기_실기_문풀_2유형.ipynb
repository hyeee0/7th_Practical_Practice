{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "l8DH7Ig1nQnu",
        "cORFnCPhnTev",
        "O3-v53-1nXNA",
        "HPwb7OtPta5f",
        "LGURuT9enW97",
        "cxnR-RGOmIS9"
      ],
      "authorship_tag": "ABX9TyNqAZRujrUCIOqkhpSu73SQ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hyeee0/7th_Practical_Practice/blob/main/7%ED%9A%8C%EC%B0%A8_%EB%B9%85%EB%B6%84%EA%B8%B0_%EC%8B%A4%EA%B8%B0_%EB%AC%B8%ED%92%80_2%EC%9C%A0%ED%98%95.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2유형 연습하기_와인종류분류"
      ],
      "metadata": {
        "id": "l8DH7Ig1nQnu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1) 라이브러리 및 데이터 확인"
      ],
      "metadata": {
        "id": "cORFnCPhnTev"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "9FVFO8ApniU1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import sklearn\n",
        "print(sklearn.__all__)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gzO8VIHipXG2",
        "outputId": "5c756b6a-b562-4416-c796-1ed1283c122a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['calibration', 'cluster', 'covariance', 'cross_decomposition', 'datasets', 'decomposition', 'dummy', 'ensemble', 'exceptions', 'experimental', 'externals', 'feature_extraction', 'feature_selection', 'gaussian_process', 'inspection', 'isotonic', 'kernel_approximation', 'kernel_ridge', 'linear_model', 'manifold', 'metrics', 'mixture', 'model_selection', 'multiclass', 'multioutput', 'naive_bayes', 'neighbors', 'neural_network', 'pipeline', 'preprocessing', 'random_projection', 'semi_supervised', 'svm', 'tree', 'discriminant_analysis', 'impute', 'compose', 'clone', 'get_config', 'set_config', 'config_context', 'show_versions']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sklearn.preprocessing\n",
        "print(sklearn.preprocessing.__all__)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AIH4ZzfQo2fq",
        "outputId": "7fb806d0-61e6-4acb-8629-2eb96fb6a11e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Binarizer', 'FunctionTransformer', 'KBinsDiscretizer', 'KernelCenterer', 'LabelBinarizer', 'LabelEncoder', 'MultiLabelBinarizer', 'MinMaxScaler', 'MaxAbsScaler', 'QuantileTransformer', 'Normalizer', 'OneHotEncoder', 'OrdinalEncoder', 'PowerTransformer', 'RobustScaler', 'SplineTransformer', 'StandardScaler', 'add_dummy_feature', 'PolynomialFeatures', 'binarize', 'normalize', 'scale', 'robust_scale', 'maxabs_scale', 'minmax_scale', 'label_binarize', 'quantile_transform', 'power_transform']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sklearn.model_selection\n",
        "print(help(sklearn.model_selection.train_test_split))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9fbm0aWZp5hN",
        "outputId": "d64ac0c5-24ae-4dad-d074-1f4eb423bdf5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Help on function train_test_split in module sklearn.model_selection._split:\n",
            "\n",
            "train_test_split(*arrays, test_size=None, train_size=None, random_state=None, shuffle=True, stratify=None)\n",
            "    Split arrays or matrices into random train and test subsets.\n",
            "    \n",
            "    Quick utility that wraps input validation,\n",
            "    ``next(ShuffleSplit().split(X, y))``, and application to input data\n",
            "    into a single call for splitting (and optionally subsampling) data into a\n",
            "    one-liner.\n",
            "    \n",
            "    Read more in the :ref:`User Guide <cross_validation>`.\n",
            "    \n",
            "    Parameters\n",
            "    ----------\n",
            "    *arrays : sequence of indexables with same length / shape[0]\n",
            "        Allowed inputs are lists, numpy arrays, scipy-sparse\n",
            "        matrices or pandas dataframes.\n",
            "    \n",
            "    test_size : float or int, default=None\n",
            "        If float, should be between 0.0 and 1.0 and represent the proportion\n",
            "        of the dataset to include in the test split. If int, represents the\n",
            "        absolute number of test samples. If None, the value is set to the\n",
            "        complement of the train size. If ``train_size`` is also None, it will\n",
            "        be set to 0.25.\n",
            "    \n",
            "    train_size : float or int, default=None\n",
            "        If float, should be between 0.0 and 1.0 and represent the\n",
            "        proportion of the dataset to include in the train split. If\n",
            "        int, represents the absolute number of train samples. If None,\n",
            "        the value is automatically set to the complement of the test size.\n",
            "    \n",
            "    random_state : int, RandomState instance or None, default=None\n",
            "        Controls the shuffling applied to the data before applying the split.\n",
            "        Pass an int for reproducible output across multiple function calls.\n",
            "        See :term:`Glossary <random_state>`.\n",
            "    \n",
            "    shuffle : bool, default=True\n",
            "        Whether or not to shuffle the data before splitting. If shuffle=False\n",
            "        then stratify must be None.\n",
            "    \n",
            "    stratify : array-like, default=None\n",
            "        If not None, data is split in a stratified fashion, using this as\n",
            "        the class labels.\n",
            "        Read more in the :ref:`User Guide <stratification>`.\n",
            "    \n",
            "    Returns\n",
            "    -------\n",
            "    splitting : list, length=2 * len(arrays)\n",
            "        List containing train-test split of inputs.\n",
            "    \n",
            "        .. versionadded:: 0.16\n",
            "            If the input is sparse, the output will be a\n",
            "            ``scipy.sparse.csr_matrix``. Else, output type is the same as the\n",
            "            input type.\n",
            "    \n",
            "    Examples\n",
            "    --------\n",
            "    >>> import numpy as np\n",
            "    >>> from sklearn.model_selection import train_test_split\n",
            "    >>> X, y = np.arange(10).reshape((5, 2)), range(5)\n",
            "    >>> X\n",
            "    array([[0, 1],\n",
            "           [2, 3],\n",
            "           [4, 5],\n",
            "           [6, 7],\n",
            "           [8, 9]])\n",
            "    >>> list(y)\n",
            "    [0, 1, 2, 3, 4]\n",
            "    \n",
            "    >>> X_train, X_test, y_train, y_test = train_test_split(\n",
            "    ...     X, y, test_size=0.33, random_state=42)\n",
            "    ...\n",
            "    >>> X_train\n",
            "    array([[4, 5],\n",
            "           [0, 1],\n",
            "           [6, 7]])\n",
            "    >>> y_train\n",
            "    [2, 0, 3]\n",
            "    >>> X_test\n",
            "    array([[2, 3],\n",
            "           [8, 9]])\n",
            "    >>> y_test\n",
            "    [1, 4]\n",
            "    \n",
            "    >>> train_test_split(y, shuffle=False)\n",
            "    [[0, 1, 2], [3, 4]]\n",
            "\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_wine\n",
        "\n",
        "wine = load_wine()\n",
        "x = pd.DataFrame(wine.data, columns=wine.feature_names)\n",
        "y = pd.DataFrame(wine.target)\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.2, stratify = y, random_state=2023)\n",
        "\n",
        "x_test = pd.DataFrame(x_test)\n",
        "x_train = pd.DataFrame(x_train)\n",
        "y_train = pd.DataFrame(y_train)\n",
        "\n",
        "x_test.reset_index()\n",
        "y_train.columns = ['target']"
      ],
      "metadata": {
        "id": "fGVmUEbanwM8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "와인의 종류를 분류해보자\n",
        "- 데이터의 결측치, 이상치에 대해 처리하고\n",
        "- 분류모델을 사용하여 정확도, F1 score, AUC 값을 산출하시오.\n",
        "- 제출은 result 변수에 담아 양식에 맞게 제출하시오"
      ],
      "metadata": {
        "id": "XiDPhw3LsAKK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2) 데이터 탐색(EDA)"
      ],
      "metadata": {
        "id": "O3-v53-1nXNA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 데이터의 행/열 확인\n",
        "\n",
        "print(x_test.shape)\n",
        "print(x_train.shape)\n",
        "print(y_train.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lk9OtE9fsGXJ",
        "outputId": "56d657b5-89c3-475a-b99b-8d236cdc9630"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(36, 13)\n",
            "(142, 13)\n",
            "(142, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 초기 데이터 확인\n",
        "\n",
        "print(x_test.head(3))\n",
        "print(x_train.head(3))\n",
        "print(y_train.head(3))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EecMctLssgs0",
        "outputId": "1c3b09cf-0190-4cb1-eefa-5e3a79c1c024"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     alcohol  malic_acid   ash  alcalinity_of_ash  magnesium  total_phenols  \\\n",
            "168    13.58        2.58  2.69               24.5      105.0           1.55   \n",
            "144    12.25        3.88  2.20               18.5      112.0           1.38   \n",
            "151    12.79        2.67  2.48               22.0      112.0           1.48   \n",
            "\n",
            "     flavanoids  nonflavanoid_phenols  proanthocyanins  color_intensity   hue  \\\n",
            "168        0.84                  0.39             1.54             8.66  0.74   \n",
            "144        0.78                  0.29             1.14             8.21  0.65   \n",
            "151        1.36                  0.24             1.26            10.80  0.48   \n",
            "\n",
            "     od280/od315_of_diluted_wines  proline  \n",
            "168                          1.80    750.0  \n",
            "144                          2.00    855.0  \n",
            "151                          1.47    480.0  \n",
            "     alcohol  malic_acid   ash  alcalinity_of_ash  magnesium  total_phenols  \\\n",
            "52     13.82        1.75  2.42               14.0      111.0           3.88   \n",
            "146    13.88        5.04  2.23               20.0       80.0           0.98   \n",
            "44     13.05        1.77  2.10               17.0      107.0           3.00   \n",
            "\n",
            "     flavanoids  nonflavanoid_phenols  proanthocyanins  color_intensity   hue  \\\n",
            "52         3.74                  0.32             1.87             7.05  1.01   \n",
            "146        0.34                  0.40             0.68             4.90  0.58   \n",
            "44         3.00                  0.28             2.03             5.04  0.88   \n",
            "\n",
            "     od280/od315_of_diluted_wines  proline  \n",
            "52                           3.26   1190.0  \n",
            "146                          1.33    415.0  \n",
            "44                           3.35    885.0  \n",
            "     target\n",
            "52        0\n",
            "146       2\n",
            "44        0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 변수명과 데이터 타입이 매칭이 되는지, 결측치가 있는지 확인해본다\n",
        "\n",
        "print(x_test.info())\n",
        "print(x_train.info())\n",
        "print(y_train.info())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mJXc5QUmsglO",
        "outputId": "4468558a-416d-40bf-e23d-e91f569ce4e2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 36 entries, 168 to 55\n",
            "Data columns (total 13 columns):\n",
            " #   Column                        Non-Null Count  Dtype  \n",
            "---  ------                        --------------  -----  \n",
            " 0   alcohol                       36 non-null     float64\n",
            " 1   malic_acid                    36 non-null     float64\n",
            " 2   ash                           36 non-null     float64\n",
            " 3   alcalinity_of_ash             36 non-null     float64\n",
            " 4   magnesium                     36 non-null     float64\n",
            " 5   total_phenols                 36 non-null     float64\n",
            " 6   flavanoids                    36 non-null     float64\n",
            " 7   nonflavanoid_phenols          36 non-null     float64\n",
            " 8   proanthocyanins               36 non-null     float64\n",
            " 9   color_intensity               36 non-null     float64\n",
            " 10  hue                           36 non-null     float64\n",
            " 11  od280/od315_of_diluted_wines  36 non-null     float64\n",
            " 12  proline                       36 non-null     float64\n",
            "dtypes: float64(13)\n",
            "memory usage: 3.9 KB\n",
            "None\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 142 entries, 52 to 115\n",
            "Data columns (total 13 columns):\n",
            " #   Column                        Non-Null Count  Dtype  \n",
            "---  ------                        --------------  -----  \n",
            " 0   alcohol                       142 non-null    float64\n",
            " 1   malic_acid                    142 non-null    float64\n",
            " 2   ash                           142 non-null    float64\n",
            " 3   alcalinity_of_ash             142 non-null    float64\n",
            " 4   magnesium                     142 non-null    float64\n",
            " 5   total_phenols                 142 non-null    float64\n",
            " 6   flavanoids                    142 non-null    float64\n",
            " 7   nonflavanoid_phenols          142 non-null    float64\n",
            " 8   proanthocyanins               142 non-null    float64\n",
            " 9   color_intensity               142 non-null    float64\n",
            " 10  hue                           142 non-null    float64\n",
            " 11  od280/od315_of_diluted_wines  142 non-null    float64\n",
            " 12  proline                       142 non-null    float64\n",
            "dtypes: float64(13)\n",
            "memory usage: 15.5 KB\n",
            "None\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 142 entries, 52 to 115\n",
            "Data columns (total 1 columns):\n",
            " #   Column  Non-Null Count  Dtype\n",
            "---  ------  --------------  -----\n",
            " 0   target  142 non-null    int64\n",
            "dtypes: int64(1)\n",
            "memory usage: 2.2 KB\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# x_train과 x_test 데이터의 기초통계량을 잘 비교해보자\n",
        "\n",
        "print(x_test.describe())\n",
        "print(x_train.describe())\n",
        "print(y_train.describe())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ugi24vcHtBbZ",
        "outputId": "203ccf04-d10c-489a-ee91-ed3e5642abcd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "         alcohol  malic_acid        ash  alcalinity_of_ash   magnesium  \\\n",
            "count  36.000000   36.000000  36.000000           36.00000   36.000000   \n",
            "mean   12.900833    2.265556   2.470278           20.05000  103.722222   \n",
            "std     0.813112    1.021943   0.226066            2.70275   16.371772   \n",
            "min    11.640000    0.890000   2.000000           14.60000   84.000000   \n",
            "25%    12.230000    1.592500   2.300000           18.00000   91.500000   \n",
            "50%    12.835000    1.885000   2.470000           19.50000  101.000000   \n",
            "75%    13.635000    2.792500   2.605000           21.70000  112.000000   \n",
            "max    14.390000    4.950000   3.220000           26.50000  162.000000   \n",
            "\n",
            "       total_phenols  flavanoids  nonflavanoid_phenols  proanthocyanins  \\\n",
            "count      36.000000   36.000000             36.000000        36.000000   \n",
            "mean        2.261667    1.972778              0.363333         1.653333   \n",
            "std         0.600259    0.858882              0.125516         0.558012   \n",
            "min         1.350000    0.660000              0.130000         0.840000   \n",
            "25%         1.715000    1.175000              0.267500         1.320000   \n",
            "50%         2.420000    2.175000              0.395000         1.550000   \n",
            "75%         2.602500    2.682500              0.435000         1.972500   \n",
            "max         3.850000    3.490000              0.660000         3.280000   \n",
            "\n",
            "       color_intensity        hue  od280/od315_of_diluted_wines     proline  \n",
            "count        36.000000  36.000000                     36.000000    36.00000  \n",
            "mean          5.267222   0.985278                      2.643611   765.75000  \n",
            "std           2.915076   0.258694                      0.720100   309.94851  \n",
            "min           2.080000   0.480000                      1.290000   278.00000  \n",
            "25%           2.875000   0.787500                      2.037500   542.50000  \n",
            "50%           4.325000   0.985000                      2.790000   682.50000  \n",
            "75%           6.900000   1.167500                      3.192500   996.25000  \n",
            "max          11.750000   1.450000                      4.000000  1480.00000  \n",
            "          alcohol  malic_acid         ash  alcalinity_of_ash   magnesium  \\\n",
            "count  142.000000  142.000000  142.000000         142.000000  142.000000   \n",
            "mean    13.025915    2.354296    2.340211          19.354225   98.732394   \n",
            "std      0.812423    1.142722    0.279910           3.476825   13.581859   \n",
            "min     11.030000    0.740000    1.360000          10.600000   70.000000   \n",
            "25%     12.370000    1.610000    2.190000          16.800000   88.000000   \n",
            "50%     13.050000    1.820000    2.320000          19.300000   97.000000   \n",
            "75%     13.685000    3.115000    2.510000          21.500000  106.750000   \n",
            "max     14.830000    5.800000    3.230000          30.000000  151.000000   \n",
            "\n",
            "       total_phenols  flavanoids  nonflavanoid_phenols  proanthocyanins  \\\n",
            "count     142.000000  142.000000            142.000000       142.000000   \n",
            "mean        2.303592    2.043592              0.361479         1.575070   \n",
            "std         0.633955    1.033597              0.124627         0.576798   \n",
            "min         0.980000    0.340000              0.140000         0.410000   \n",
            "25%         1.757500    1.227500              0.270000         1.242500   \n",
            "50%         2.335000    2.100000              0.325000         1.555000   \n",
            "75%         2.800000    2.917500              0.437500         1.950000   \n",
            "max         3.880000    5.080000              0.630000         3.580000   \n",
            "\n",
            "       color_intensity         hue  od280/od315_of_diluted_wines      proline  \n",
            "count       142.000000  142.000000                    142.000000   142.000000  \n",
            "mean          5.005070    0.950394                      2.603592   742.112676  \n",
            "std           2.150186    0.220736                      0.709751   317.057395  \n",
            "min           1.280000    0.540000                      1.270000   290.000000  \n",
            "25%           3.300000    0.782500                      1.922500   496.250000  \n",
            "50%           4.850000    0.960000                      2.780000   660.000000  \n",
            "75%           6.122500    1.097500                      3.170000   981.250000  \n",
            "max          13.000000    1.710000                      3.920000  1680.000000  \n",
            "           target\n",
            "count  142.000000\n",
            "mean     0.936620\n",
            "std      0.773816\n",
            "min      0.000000\n",
            "25%      0.000000\n",
            "50%      1.000000\n",
            "75%      2.000000\n",
            "max      2.000000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# y 데이터도 구체적으로 살펴보자\n",
        "print(y_train.head())\n",
        "print(y_train.value_counts())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FJVYWml-tBZL",
        "outputId": "f3dbbc86-908d-4eba-f2e6-8be086d31568"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     target\n",
            "52        0\n",
            "146       2\n",
            "44        0\n",
            "67        1\n",
            "43        0\n",
            "target\n",
            "1         57\n",
            "0         47\n",
            "2         38\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3) 데이터 전처리 및 분리"
      ],
      "metadata": {
        "id": "yjmTjnX2nXFc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1) 결측치, 2) 이상치, 3) 변수 처리하기"
      ],
      "metadata": {
        "id": "HPwb7OtPta5f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 결측치 확인\n",
        "print(x_test.isnull().sum())\n",
        "print(x_train.isnull().sum())\n",
        "print(y_train.isnull().sum())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7t_BQKg7tgR2",
        "outputId": "dca2fc62-e16d-464c-9ccb-0a11b47d7861"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "alcohol                         0\n",
            "malic_acid                      0\n",
            "ash                             0\n",
            "alcalinity_of_ash               0\n",
            "magnesium                       0\n",
            "total_phenols                   0\n",
            "flavanoids                      0\n",
            "nonflavanoid_phenols            0\n",
            "proanthocyanins                 0\n",
            "color_intensity                 0\n",
            "hue                             0\n",
            "od280/od315_of_diluted_wines    0\n",
            "proline                         0\n",
            "dtype: int64\n",
            "alcohol                         0\n",
            "malic_acid                      0\n",
            "ash                             0\n",
            "alcalinity_of_ash               0\n",
            "magnesium                       0\n",
            "total_phenols                   0\n",
            "flavanoids                      0\n",
            "nonflavanoid_phenols            0\n",
            "proanthocyanins                 0\n",
            "color_intensity                 0\n",
            "hue                             0\n",
            "od280/od315_of_diluted_wines    0\n",
            "proline                         0\n",
            "dtype: int64\n",
            "target    0\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 결측치 제거\n",
        "df = df.dropna()\n",
        "print(df)\n",
        "\n",
        "# 참고사항\n",
        "print(df.dropna().shape) # 헹 기준으로 삭제\n",
        "\n",
        "# ★주의사항\n",
        "# x_train의 행을 제거해야 하는 경우, 그에 해당하는 y_train 행도 제거해야 합니다.\n",
        "# 해결방법 : train = pd.concat([x_train, y_train], axis=1)\n",
        "# 위와 같이 데이터를 결합한 후에 행을 제거하고 다시 데이터 분리를 수행하면 됩니다.\n",
        "# (만약 원데이터가 x_train/y_train이 결합된 형태로 주어진다면 전처리를 모두 수행한 후에 분리하셔도 됩니다)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 258
        },
        "id": "7yf5nNVKt9lw",
        "outputId": "242ee596-2d13-4d74-ed6e-ef0b913788fc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-23-aa095c3af021>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# 결측치 제거\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# 참고사항\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 결측치 대체(평균값, 중앙값, 최빈값)\n",
        "# ** 주의사항 : train 데이터의 중앙값/평균값/최빈값 등으로 test 데이터의 결측치도 변경해줘야 함 **\n",
        "# 연속형 변수 : 중앙값, 평균값\n",
        "# - df['변수명'].median()\n",
        "# - df['변수명'].mean()\n",
        "# 범주형 변수 : 최빈값\n",
        "# df['변수명'] = df['변수명'].fillna(대체할 값)"
      ],
      "metadata": {
        "id": "4VA-lwT5uMni"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 이상치 대체(예시)\n",
        "# df['변수명'] = np.where( df['변수명'] >= 5, 대체할 값, df['변수명'] )"
      ],
      "metadata": {
        "id": "ezm2PzZYuMiz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 변수처리\n",
        "# 불필요한 변수 제거\n",
        "# df = df.drop(columns = ['변수1','변수2'])\n",
        "# df = df.drop(['변수1','변수2'], axis=1)\n",
        "# 필요시 변수 추가(파생변수 생성)\n",
        "# df['파생변수명'] = df['A'] * df['B'] (파생변수 생성 수식)\n",
        "# 원핫인코딩(가변수 처리)\n",
        "# x_train = pd.get_dummies(x_train)\n",
        "# x_test = pd.get_dummies(x_test)\n",
        "# print(x_train.info())\n",
        "# print(x_test.info())"
      ],
      "metadata": {
        "id": "jRpf4vRluPoa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(help(sklearn.model_selection.train_test_split))"
      ],
      "metadata": {
        "id": "f_oDVR_SvHVU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 데이터 분리\n",
        "# 데이터를 훈련세트와 검증용 세트로 분할 (80% 훈련, 20% 검증용)\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train['target'], test_size = 0.2, stratify = y_train['target'], random_state=2023)\n",
        "\n",
        "print(x_train.shape)\n",
        "print(x_val.shape)\n",
        "print(y_train.shape)\n",
        "print(y_val.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l8JRhsLluQrT",
        "outputId": "444e2ebf-5ed4-4381-b9dd-2eaeff26356e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(113, 13)\n",
            "(29, 13)\n",
            "(113,)\n",
            "(29,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4) 모델링 및 성능평가"
      ],
      "metadata": {
        "id": "LGURuT9enW97"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import sklearn\n",
        "print(sklearn.__all__)"
      ],
      "metadata": {
        "id": "PF1BQAp6wJry"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import sklearn.ensemble\n",
        "print(sklearn.ensemble.__all__)"
      ],
      "metadata": {
        "id": "gs8dH6o8wWCo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 랜덤포레스트 모델 사용 (참고 : 회귀모델은 RandomForestRegressor)\n",
        "\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "model = RandomForestClassifier()\n",
        "model.fit(x_train, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 75
        },
        "id": "9pOaJqaWwDYD",
        "outputId": "47011f75-6060-475a-e65a-102809c076ff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomForestClassifier()"
            ],
            "text/html": [
              "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier()</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 모델을 사용하여 테스트 데이터 예측\n",
        "\n",
        "y_pred = model.predict(x_val)"
      ],
      "metadata": {
        "id": "9p-5fI4rwDVe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import sklearn.metrics\n",
        "print(sklearn.metrics.__all__)"
      ],
      "metadata": {
        "id": "evRLJhkX9VW4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(help(sklearn.metrics.f1_score))"
      ],
      "metadata": {
        "id": "OzbWih5b-Mi4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 모델 성능 평가 (정확도, F1 score, 민감도, 특이도 등)\n",
        "\n",
        "from sklearn.metrics import accuracy_score, f1_score, recall_score, precision_score\n",
        "acc = accuracy_score(y_val, y_pred) # (실제값, 예측값)\n",
        "f1 = f1_score(y_val, y_pred, average='macro') # 클래스가 불균형 할 경우에는 averagre='micro'\n",
        "# auc = roc_auc_score(y_val, y_pred) # AUC는 이진분류\n"
      ],
      "metadata": {
        "id": "lcTuims6wDSA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#정확도(Accuracy)\n",
        "print(acc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_2O2zChh-29k",
        "outputId": "abd8e461-9f29-4d31-c5c6-94b49aa9fafc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# macro f1 score\n",
        "print(f1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e8m9xMQH--PG",
        "outputId": "3dedaf19-ac79-4a72-d837-29d74eec3c31"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5) 예측값 제출\n",
        "(주의) test 셋을 모델에 넣어 나온 예측값을 제출해야함"
      ],
      "metadata": {
        "id": "ilJSaNvJnfh5"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XOfv1GwynG5S",
        "outputId": "b6721368-eafd-4853-b05f-79bc4cab8c38"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2 2 2 0 1]\n",
            "[[0.01 0.01 0.98]\n",
            " [0.1  0.12 0.78]\n",
            " [0.   0.07 0.93]\n",
            " [0.99 0.   0.01]\n",
            " [0.02 0.85 0.13]]\n",
            "   result  prob_0  prob_1  prob_2\n",
            "0       2    0.01    0.01    0.98\n",
            "1       2    0.10    0.12    0.78\n",
            "2       2    0.00    0.07    0.93\n",
            "3       0    0.99    0.00    0.01\n",
            "4       1    0.02    0.85    0.13\n"
          ]
        }
      ],
      "source": [
        "# (실기시험 안내사항)\n",
        "# 아래 코드 예측변수와 수험번호를 개인별로 변경하여 활용\n",
        "# pd.DataFrame({ 'result': y_result }).to_csv('수험번호.csv', index=False)\n",
        "# 모델을 사용하여 테스트 데이터 예측\n",
        "\n",
        "# 1. 특정 클래스로 분류할 경우 (predict)\n",
        "y_result = model.predict(x_test)\n",
        "print(y_result[:5])\n",
        "\n",
        "# 2. 특정 클래스로 분류될 확률을 구할 경우 (predict_proba)\n",
        "y_result_prob = model.predict_proba(x_test)\n",
        "print(y_result_prob[:5])\n",
        "\n",
        "# 이해해보기\n",
        "result_prob = pd.DataFrame({\n",
        "'result': y_result,\n",
        "'prob_0': y_result_prob[:,0],\n",
        "'prob_1': y_result_prob[:,1],\n",
        "'prob_2': y_result_prob[:,2]\n",
        "})\n",
        "# Class 0일 확률 : y_result_prob[:,0]\n",
        "# Class 1일 확률 : y_result_prob[:,1]\n",
        "# Class 2일 확률 : y_result_prob[:,2]\n",
        "\n",
        "print(result_prob[:5])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ★tip : 데이터를 저장한다음 불러와서 제대로 제출했는지 확인해보자\n",
        "pd.DataFrame({'result': y_result}).to_csv('수험번호.csv', index=False)\n",
        "df2 = pd.read_csv(\"수험번호.csv\")\n",
        "print(df2.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q3sOV77-h5nW",
        "outputId": "38453895-f917-4b56-9ce1-cfc9d1ad8473"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   result\n",
            "0       2\n",
            "1       2\n",
            "2       2\n",
            "3       0\n",
            "4       1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 제2유형_연습하기_iris 종 분류\n",
        "\n",
        "✅ 데이터 분석 순서\n",
        "1. 라이브러리 및 데이터 확인\n",
        "2. 데이터 탐색(EDA)\n",
        "3. 데이터 전처리 및 분리\n",
        "4. 모델링 및 성능평가\n",
        "5. 예측값 제출"
      ],
      "metadata": {
        "id": "fKyy9hsLi6-0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1) 라이브러리 및 데이터 확인"
      ],
      "metadata": {
        "id": "Q-UWe0BDjAeT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "43e8XfIgjFxV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "# 실기 시험 데이터셋으로 셋팅하기 (수정금지)\n",
        "from sklearn.datasets import load_iris\n",
        "# Iris 데이터셋을 로드\n",
        "iris = load_iris()\n",
        "x = pd.DataFrame(iris.data, columns=['sepal_length', 'sepal_width', 'petal_length', 'petal_width'])\n",
        "y = iris.target # 'setosa'=0, 'versicolor'=1, 'virginica'=2\n",
        "y = np.where(y>0, 1, 0) # setosa 종은 0, 나머지 종은 1로 변경\n",
        "# 실기 시험 데이터셋으로 셋팅하기 (수정금지)\n",
        "from sklearn.model_selection import train_test_split\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2,\n",
        "stratify=y,\n",
        "random_state=2023)\n",
        "x_test = pd.DataFrame(x_test)\n",
        "x_train = pd.DataFrame(x_train)\n",
        "y_train = pd.DataFrame(y_train)\n",
        "y_train.columns = ['species']\n",
        "# 결측치 삽입\n",
        "x_test['sepal_length'].iloc[0] = None\n",
        "x_train['sepal_length'].iloc[0] = None\n",
        "# 이상치 삽입\n",
        "x_train['sepal_width'].iloc[0] = 150"
      ],
      "metadata": {
        "id": "d0lnp8_yjO3E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "붓꽃의 종(Species)을 분류해보자\n",
        "- 데이터의 결측치, 이상치에 대해 처리하고\n",
        "- 분류모델을 사용하여 정확도, F1 score, AUC 값을 산출하시오.\n",
        "- 제출은 result 변수에 담아 양식에 맞게 제출하시오"
      ],
      "metadata": {
        "id": "PJQf2P9vjT5e"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2) 데이터 탐색(EDA)"
      ],
      "metadata": {
        "id": "prR-a40ljYCJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 데이터의 행/열 확인\n",
        "\n",
        "print(x_train.shape)\n",
        "print(y_train.shape)\n",
        "print(x_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "afAM75CUjTHq",
        "outputId": "568a9203-36bf-46a1-c2a7-893dc4a79a52"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(120, 4)\n",
            "(120, 1)\n",
            "(30, 4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 초기 데이터 확인\n",
        "\n",
        "print(x_train.head(3))\n",
        "print(x_test.head(3))\n",
        "print(y_train.head(3))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oYrnwo1AjoDw",
        "outputId": "5e396bff-a8d8-47c3-c036-f34eb276c9da"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    sepal_length  sepal_width  petal_length  petal_width\n",
            "2            NaN        150.0           1.3          0.2\n",
            "49           5.0          3.3           1.4          0.2\n",
            "66           5.6          3.0           4.5          1.5\n",
            "     sepal_length  sepal_width  petal_length  petal_width\n",
            "93            NaN          2.3           3.3          1.0\n",
            "69            5.6          2.5           3.9          1.1\n",
            "137           6.4          3.1           5.5          1.8\n",
            "   species\n",
            "0        0\n",
            "1        0\n",
            "2        1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 데이터 결측치 확인\n",
        "\n",
        "print(x_train.info())\n",
        "print(x_test.info())\n",
        "print(y_train.info())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qdjkLyaKjyJX",
        "outputId": "bac66212-1f4f-44cf-e933-b9802ba8ca78"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 120 entries, 2 to 44\n",
            "Data columns (total 4 columns):\n",
            " #   Column        Non-Null Count  Dtype  \n",
            "---  ------        --------------  -----  \n",
            " 0   sepal_length  119 non-null    float64\n",
            " 1   sepal_width   120 non-null    float64\n",
            " 2   petal_length  120 non-null    float64\n",
            " 3   petal_width   120 non-null    float64\n",
            "dtypes: float64(4)\n",
            "memory usage: 4.7 KB\n",
            "None\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 30 entries, 93 to 55\n",
            "Data columns (total 4 columns):\n",
            " #   Column        Non-Null Count  Dtype  \n",
            "---  ------        --------------  -----  \n",
            " 0   sepal_length  29 non-null     float64\n",
            " 1   sepal_width   30 non-null     float64\n",
            " 2   petal_length  30 non-null     float64\n",
            " 3   petal_width   30 non-null     float64\n",
            "dtypes: float64(4)\n",
            "memory usage: 1.2 KB\n",
            "None\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 120 entries, 0 to 119\n",
            "Data columns (total 1 columns):\n",
            " #   Column   Non-Null Count  Dtype\n",
            "---  ------   --------------  -----\n",
            " 0   species  120 non-null    int64\n",
            "dtypes: int64(1)\n",
            "memory usage: 1.1 KB\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# x_train과 x_test 데이터의 기초통계량을 비교\n",
        "\n",
        "print(x_train.describe())\n",
        "print(x_test.describe())\n",
        "print(y_train.describe())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Eckm4Fu2uYhf",
        "outputId": "af1b2bcb-c57a-4f4d-ab92-e4e235e9acbe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "       sepal_length  sepal_width  petal_length  petal_width\n",
            "count    119.000000     120.0000    120.000000   120.000000\n",
            "mean       5.920168       4.2950      3.816667     1.226667\n",
            "std        0.841667      13.4191      1.798848     0.780512\n",
            "min        4.300000       2.2000      1.100000     0.100000\n",
            "25%        5.150000       2.8000      1.575000     0.300000\n",
            "50%        6.000000       3.0000      4.400000     1.350000\n",
            "75%        6.500000       3.4000      5.225000     1.800000\n",
            "max        7.900000     150.0000      6.900000     2.500000\n",
            "       sepal_length  sepal_width  petal_length  petal_width\n",
            "count     29.000000    30.000000     30.000000     30.00000\n",
            "mean       5.596552     3.000000      3.523333      1.09000\n",
            "std        0.709367     0.522593      1.631518      0.68549\n",
            "min        4.600000     2.000000      1.000000      0.10000\n",
            "25%        5.000000     2.625000      1.600000      0.35000\n",
            "50%        5.500000     3.000000      4.050000      1.15000\n",
            "75%        5.900000     3.300000      4.925000      1.57500\n",
            "max        7.600000     4.200000      6.600000      2.30000\n",
            "          species\n",
            "count  120.000000\n",
            "mean     0.666667\n",
            "std      0.473381\n",
            "min      0.000000\n",
            "25%      0.000000\n",
            "50%      1.000000\n",
            "75%      1.000000\n",
            "max      1.000000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# y데이터 구체적으로 살펴보기\n",
        "\n",
        "print(y_train.head())\n",
        "print(y_train.value_counts())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LJWsCiqtuv4D",
        "outputId": "f94b77ed-7b6b-45e4-faa5-fb3f9627f281"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   species\n",
            "0        0\n",
            "1        0\n",
            "2        1\n",
            "3        1\n",
            "4        1\n",
            "species\n",
            "1          80\n",
            "0          40\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3) 데이터 전처리 및 분리\n",
        "1) 결측치, 2) 이상치, 3) 변수 처리하기"
      ],
      "metadata": {
        "id": "cQ9xIHLWu724"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 결측치 확인\n",
        "print(x_train.isnull().sum())\n",
        "print(x_test.isnull().sum())\n",
        "print(y_train.isnull().sum())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1KPAR4zfu_x6",
        "outputId": "89af7290-06fa-42fd-bfec-4155f3ae686b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sepal_length    1\n",
            "sepal_width     0\n",
            "petal_length    0\n",
            "petal_width     0\n",
            "dtype: int64\n",
            "sepal_length    1\n",
            "sepal_width     0\n",
            "petal_length    0\n",
            "petal_width     0\n",
            "dtype: int64\n",
            "species    0\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 결측치 제거\n",
        "# df = df.dropna()\n",
        "# print(df)\n",
        "\n",
        "# 참고사항\n",
        "# print(df.dropna().shape) # 행 기준으로 삭제\n",
        "\n",
        "# ★주의사항\n",
        "# x_train의 행을 제거해야 하는 경우, 그에 해당하는 y_train 행도 제거해야 합니다.\n",
        "# 해결방법 : train = pd.concat([x_train, y_train], axis=1)\n",
        "# 위와 같이 데이터를 결합한 후에 행을 제거하고 다시 데이터 분리를 수행하면 됩니다.\n",
        "# (만약 원데이터가 x_train/y_train이 결합된 형태로 주어진다면 전처리를 모두 수행한 후에 분리하셔도 됩니다)"
      ],
      "metadata": {
        "id": "4ZmmZUOVvLMl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 결측치 대체(평균값, 중앙값, 최빈값)\n",
        "# ** 주의사항 : train 데이터의 중앙값/평균값/최빈값 등으로 test 데이터의 결측치도 변경해줘야 함 **\n",
        "\n",
        "# 연속형 변수 : 중앙값, 평균값\n",
        "# - df['변수명'].median()\n",
        "# - df['변수명'].mean()\n",
        "\n",
        "# 범주형 변수 : 최빈값\n",
        "# df['변수명'] = df['변수명'].fillna(대체할 값)"
      ],
      "metadata": {
        "id": "1hxxgOCRvM37"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 결측치 대체(중앙값)\n",
        "# ** 주의사항 : train 데이터의 중앙값으로 test 데이터도 변경해줘야 함 **\n",
        "\n",
        "median = x_train['sepal_length'].median()  #train 데이터의 중앙\n",
        "x_train['sepal_length'] = x_train['sepal_length'].fillna(median)\n",
        "x_test['sepal_length'] = x_test['sepal_length'].fillna(median)"
      ],
      "metadata": {
        "id": "0KJMUrA-vOba"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 이상치 확인\n",
        "cond1 = (x_train['sepal_width']>=10)\n",
        "print(len(x_train[cond1]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SPUllIuRvjhU",
        "outputId": "fa83330e-f4c7-47a8-8102-d527685e830b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 이상치 대체\n",
        "# (참고) df['변수명'] = np.where( df['변수명'] >= 5, 대체할 값, df['변수명'] )\n",
        "# 예를 들어 'sepal_width' 값이 10이 넘으면 이상치라고 가정해본다면\n",
        "# 이상치를 제외한 Max 값을 구해서 대체해보자\n",
        "\n",
        "cond1 = (x_train['sepal_width'] <= 10)\n",
        "max_sw = x_train[cond1]['sepal_width'].max()\n",
        "print(max_sw)\n",
        "x_train['sepal_width'] = np.where( x_train['sepal_width'] >= 10, max_sw, x_train['sepal_width'] )\n",
        "print(x_train.describe())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5FmJPPfYv4oO",
        "outputId": "19f01fa7-6823-4512-e63c-d47d25720ec4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4.4\n",
            "       sepal_length  sepal_width  petal_length  petal_width\n",
            "count    120.000000   120.000000    120.000000   120.000000\n",
            "mean       5.920833     3.081667      3.816667     1.226667\n",
            "std        0.838155     0.429966      1.798848     0.780512\n",
            "min        4.300000     2.200000      1.100000     0.100000\n",
            "25%        5.175000     2.800000      1.575000     0.300000\n",
            "50%        6.000000     3.000000      4.400000     1.350000\n",
            "75%        6.500000     3.400000      5.225000     1.800000\n",
            "max        7.900000     4.400000      6.900000     2.500000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 변수처리\n",
        "# 불필요한 변수 제거\n",
        "# df = df.drop(columns = ['변수1','변수2'])\n",
        "# df = df.drop(['변수1','변수2'], axis=1)\n",
        "\n",
        "# 필요시 변수 추가(파생변수 생성)\n",
        "# df['파생변수명'] = df['A'] * df['B'] (파생변수 생성 수식)\n",
        "\n",
        "# 원핫인코딩(가변수 처리)\n",
        "# x_train = pd.get_dummies(x_train)\n",
        "# x_test = pd.get_dummies(x_test)\n",
        "# print(x_train.info())\n",
        "# print(x_test.info())"
      ],
      "metadata": {
        "id": "u9AZ78KCwAgK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 데이터를 훈련 세트와 검증용 세트로 분할 (80% 훈련, 20% 검증용)\n",
        "from sklearn.model_selection import train_test_split\n",
        "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train['species'], test_size=0.2, random_state=2023)\n",
        "\n",
        "print(x_train.shape)\n",
        "print(x_val.shape)\n",
        "print(y_train.shape)\n",
        "print(y_val.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GzcV_WvKwGVc",
        "outputId": "1d170077-2481-4c6c-912c-b827db4acab7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(96, 4)\n",
            "(24, 4)\n",
            "(96,)\n",
            "(24,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4)모델링 및 성능평가"
      ],
      "metadata": {
        "id": "_cikGHd0wjh5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 랜덤포레스트 모델 사용 (참고 : 회귀모델은 RandomForestRegressor)\n",
        "\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "model = RandomForestClassifier()\n",
        "model.fit(x_train, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 75
        },
        "id": "lDCOwvu0wnT_",
        "outputId": "1b2f4d4f-2038-436a-9ec3-d39a2be1ddd7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomForestClassifier()"
            ],
            "text/html": [
              "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier()</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 모델을 사용하여 테스트 데이터 예측\n",
        "y_pred = model.predict(x_val)"
      ],
      "metadata": {
        "id": "Vbg3nnlyxCiV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import sklearn.metrics\n",
        "print(sklearn.metrics.__all__)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8cIAslO8xag3",
        "outputId": "b38ba2a0-3ad1-4cca-cc6d-7f901ef6322e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['accuracy_score', 'adjusted_mutual_info_score', 'adjusted_rand_score', 'auc', 'average_precision_score', 'balanced_accuracy_score', 'calinski_harabasz_score', 'check_scoring', 'class_likelihood_ratios', 'classification_report', 'cluster', 'cohen_kappa_score', 'completeness_score', 'ConfusionMatrixDisplay', 'confusion_matrix', 'consensus_score', 'coverage_error', 'd2_tweedie_score', 'd2_absolute_error_score', 'd2_pinball_score', 'dcg_score', 'davies_bouldin_score', 'DetCurveDisplay', 'det_curve', 'DistanceMetric', 'euclidean_distances', 'explained_variance_score', 'f1_score', 'fbeta_score', 'fowlkes_mallows_score', 'get_scorer', 'hamming_loss', 'hinge_loss', 'homogeneity_completeness_v_measure', 'homogeneity_score', 'jaccard_score', 'label_ranking_average_precision_score', 'label_ranking_loss', 'log_loss', 'make_scorer', 'nan_euclidean_distances', 'matthews_corrcoef', 'max_error', 'mean_absolute_error', 'mean_squared_error', 'mean_squared_log_error', 'mean_pinball_loss', 'mean_poisson_deviance', 'mean_gamma_deviance', 'mean_tweedie_deviance', 'median_absolute_error', 'mean_absolute_percentage_error', 'multilabel_confusion_matrix', 'mutual_info_score', 'ndcg_score', 'normalized_mutual_info_score', 'pair_confusion_matrix', 'pairwise_distances', 'pairwise_distances_argmin', 'pairwise_distances_argmin_min', 'pairwise_distances_chunked', 'pairwise_kernels', 'PrecisionRecallDisplay', 'precision_recall_curve', 'precision_recall_fscore_support', 'precision_score', 'PredictionErrorDisplay', 'r2_score', 'rand_score', 'recall_score', 'RocCurveDisplay', 'roc_auc_score', 'roc_curve', 'SCORERS', 'get_scorer_names', 'silhouette_samples', 'silhouette_score', 'top_k_accuracy_score', 'v_measure_score', 'zero_one_loss', 'brier_score_loss']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 모델 성능평가 (accuracy, f1 score, AUC 등)\n",
        "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score, recall_score, precision_score\n",
        "acc = accuracy_score(y_val, y_pred) # (실제값, 예측값)\n",
        "f1 = f1_score(y_val, y_pred)\n",
        "auc = roc_auc_score(y_val, y_pred)"
      ],
      "metadata": {
        "id": "Gwb5d6l0xRWQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(acc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jIRHlOIox8cN",
        "outputId": "debaeb58-5cbf-4ac4-a3d6-f112be78aaab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jRVK49dex-Lr",
        "outputId": "034b4360-8018-46f7-d9bf-9f4885d5307a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(auc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7VEG_lJWx_kJ",
        "outputId": "c536cede-f49f-4eea-8774-7f3e4eb980ba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 참고사항\n",
        "from sklearn.metrics import confusion_matrix\n",
        "cm = confusion_matrix(y_val, y_pred) # (실제값, 예측값)\n",
        "print(cm)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j69xW5jUyE1H",
        "outputId": "efd0ef7a-7768-4c3a-b8fd-28023fd2adda"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[11  0]\n",
            " [ 0 13]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5) 예측값 제출\n",
        "(주의) x_test 를 모델에 넣어 나온 예측값을 제출해야함"
      ],
      "metadata": {
        "id": "1bNjWnPJyIIv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# (실기시험 안내사항)\n",
        "# 아래 코드 예측변수와 수험번호를 개인별로 변경하여 활용\n",
        "# pd.DataFrame({ 'result': y_result }).to_csv('수험번호.csv', index=False)\n",
        "\n",
        "# 모델을 사용하여 테스트 데이터 예측\n",
        "\n",
        "# 1. 특정 클래스로 분류할 경우 (predict)\n",
        "y_result = model.predict(x_test)\n",
        "print(y_result[:5])\n",
        "\n",
        "# 2. 특정 클래스로 분류될 확률을 구할 경우 (predict_proba)\n",
        "y_result_prob = model.predict_proba(x_test)\n",
        "print(y_result_prob[:5])\n",
        "\n",
        "# 이해해보기\n",
        "result_prob = pd.DataFrame({\n",
        "'result': y_result,\n",
        "'prob_0': y_result_prob[:,0]\n",
        "})\n",
        "\n",
        "# setosa 일 확률 : y_result_prob[:,0]\n",
        "# 그 외 종일 확률 : y_result_prob[:,1]\n",
        "print(result_prob[:5])"
      ],
      "metadata": {
        "id": "pFtg7uN9yVYJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ★tip : 데이터를 저장한다음 불러와서 제대로 제출했는지 확인해보자\n",
        "# pd.DataFrame({'result': y_result}).to_csv('수험번호.csv', index=False)\n",
        "# df2 = pd.read_csv(\"수험번호.csv\")\n",
        "# print(df2.head())"
      ],
      "metadata": {
        "id": "iesinXxnyaQM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 제2유형_연습하기_타이타닉 생존자 분류\n",
        "✅ 데이터 분석 순서\n",
        "1. 라이브러리 및 데이터 확인\n",
        "2. 데이터 탐색(EDA)\n",
        "3. 데이터 전처리 및 분리\n",
        "4. 모델링 및 성능평가\n",
        "5. 예측값 제출"
      ],
      "metadata": {
        "id": "Pw9BOIqI1aax"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1) 라이브러리 및 데이터 확인"
      ],
      "metadata": {
        "id": "DQ1MkSoV3x0B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "CX-B__Cl3zCC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 실기 시험 데이터셋으로 셋팅하기 (수정금지)\n",
        "# Seaborn의 내장 타이타닉 데이터셋을 불러옵니다.\n",
        "import seaborn as sns\n",
        "df = sns.load_dataset('titanic')\n",
        "x = df.drop('survived', axis=1)\n",
        "y = df['survived']\n",
        "\n",
        "# 실기 시험 데이터셋으로 셋팅하기 (수정금지)\n",
        "from sklearn.model_selection import train_test_split\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, stratify=y, random_state=2023)\n",
        "\n",
        "x_test = pd.DataFrame(x_test)\n",
        "x_train = pd.DataFrame(x_train)\n",
        "y_train = pd.DataFrame(y_train)\n",
        "\n",
        "y_test = pd.DataFrame(y_test) # 평가용\n",
        "x_test.reset_index()\n",
        "y_train.columns = ['target']\n",
        "y_test.columns = ['target']"
      ],
      "metadata": {
        "id": "J0uvFelQ340M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "타이타닉 생존자 예측 문제\n",
        "- 데이터의 결측치, 중복 변수값에 대해 처리하고\n",
        "- 분류모델을 사용하여 Accuracy, F1 score, AUC 값을 산출하시오."
      ],
      "metadata": {
        "id": "xkhUa9jq4cNh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "데이터 설명\n",
        "- survival : 0 = No, 1 = Yes\n",
        "- pclass : 객실 등급(1,2,3)\n",
        "- sex : 성별\n",
        "- age : 나이\n",
        "- sibsp : 타이타닉호에 탑승한 형제/배우자의 수\n",
        "- parch : 타이타닉호에 탑승한 부모/자녀의 수\n",
        "- fare : 요금\n",
        "- embarked : 탑승지 이름(C, Q, S) Cherbourg /Queenstown / Southampton\n",
        "- (중복)class : 객실 등급(First, Second, Third)\n",
        "- who : man, women, child\n",
        "- adult_male : 성인남자인지 여부(True=성인남자, False 그외)\n",
        "- deck : 선실번호 첫 알파벳(A,B,C,D,E,F,G)\n",
        "- (중복) embark_town : 탑승지 이름(Cherbourg, Queenstown, Southampton)\n",
        "- (중복) alive : 생존여부(no:사망, yes:생존)\n",
        "- alone : 혼자 탑승했는지 여부(True=혼자, False=가족과 함께)"
      ],
      "metadata": {
        "id": "bcPNKeJ94nUI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2) 데이터 탐색(EDA)"
      ],
      "metadata": {
        "id": "O1h5_MPz39AR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 데이터의 행/열 확인\n",
        "print(x_train.shape)\n",
        "print(x_test.shape)\n",
        "print(y_train.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bpoPm-GF3_2r",
        "outputId": "6397e15a-635b-49fe-9272-5b23c9236c45"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(712, 14)\n",
            "(179, 14)\n",
            "(712, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 초기 데이터 확인\n",
        "print(x_train.head(3))\n",
        "print(x_test.head(3))\n",
        "print(y_train.head(3))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4lHcK-ID6E5x",
        "outputId": "ce38cefa-f8d6-4a14-928b-ed8a3a7084c0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     pclass     sex   age  sibsp  parch   fare embarked   class    who  \\\n",
            "3         1  female  35.0      1      0  53.10        S   First  woman   \n",
            "517       3    male   NaN      0      0  24.15        Q   Third    man   \n",
            "861       2    male  21.0      1      0  11.50        S  Second    man   \n",
            "\n",
            "     adult_male deck  embark_town alive  alone  \n",
            "3         False    C  Southampton   yes  False  \n",
            "517        True  NaN   Queenstown    no   True  \n",
            "861        True  NaN  Southampton    no  False  \n",
            "     pclass     sex   age  sibsp  parch   fare embarked   class    who  \\\n",
            "800       2    male  34.0      0      0   13.0        S  Second    man   \n",
            "341       1  female  24.0      3      2  263.0        S   First  woman   \n",
            "413       2    male   NaN      0      0    0.0        S  Second    man   \n",
            "\n",
            "     adult_male deck  embark_town alive  alone  \n",
            "800        True  NaN  Southampton    no   True  \n",
            "341       False    C  Southampton   yes  False  \n",
            "413        True  NaN  Southampton    no   True  \n",
            "     target\n",
            "3         1\n",
            "517       0\n",
            "861       0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 변수명과 데이터 타입이 매칭이 되는지, 결측치가 있는지 확인 info()\n",
        "print(x_train.info())\n",
        "print(x_test.info())\n",
        "print(y_train.info())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "54Rf4Hta6UKV",
        "outputId": "08c03f95-43d8-44fb-c5dd-c840b6ca762c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 712 entries, 3 to 608\n",
            "Data columns (total 14 columns):\n",
            " #   Column       Non-Null Count  Dtype   \n",
            "---  ------       --------------  -----   \n",
            " 0   pclass       712 non-null    int64   \n",
            " 1   sex          712 non-null    object  \n",
            " 2   age          579 non-null    float64 \n",
            " 3   sibsp        712 non-null    int64   \n",
            " 4   parch        712 non-null    int64   \n",
            " 5   fare         712 non-null    float64 \n",
            " 6   embarked     710 non-null    object  \n",
            " 7   class        712 non-null    category\n",
            " 8   who          712 non-null    object  \n",
            " 9   adult_male   712 non-null    bool    \n",
            " 10  deck         164 non-null    category\n",
            " 11  embark_town  710 non-null    object  \n",
            " 12  alive        712 non-null    object  \n",
            " 13  alone        712 non-null    bool    \n",
            "dtypes: bool(2), category(2), float64(2), int64(3), object(5)\n",
            "memory usage: 64.4+ KB\n",
            "None\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 179 entries, 800 to 410\n",
            "Data columns (total 14 columns):\n",
            " #   Column       Non-Null Count  Dtype   \n",
            "---  ------       --------------  -----   \n",
            " 0   pclass       179 non-null    int64   \n",
            " 1   sex          179 non-null    object  \n",
            " 2   age          135 non-null    float64 \n",
            " 3   sibsp        179 non-null    int64   \n",
            " 4   parch        179 non-null    int64   \n",
            " 5   fare         179 non-null    float64 \n",
            " 6   embarked     179 non-null    object  \n",
            " 7   class        179 non-null    category\n",
            " 8   who          179 non-null    object  \n",
            " 9   adult_male   179 non-null    bool    \n",
            " 10  deck         39 non-null     category\n",
            " 11  embark_town  179 non-null    object  \n",
            " 12  alive        179 non-null    object  \n",
            " 13  alone        179 non-null    bool    \n",
            "dtypes: bool(2), category(2), float64(2), int64(3), object(5)\n",
            "memory usage: 16.6+ KB\n",
            "None\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 712 entries, 3 to 608\n",
            "Data columns (total 1 columns):\n",
            " #   Column  Non-Null Count  Dtype\n",
            "---  ------  --------------  -----\n",
            " 0   target  712 non-null    int64\n",
            "dtypes: int64(1)\n",
            "memory usage: 11.1 KB\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# x_train 과 x_test 데이터의 기초통계량을 잘 비교해보세요.\n",
        "print(x_train.describe()) # x_train.describe().T 둘중에 편한거 사용하세요\n",
        "print(x_test.describe())\n",
        "print(y_train.describe())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o3Xh3FdE6154",
        "outputId": "bb1b4506-cd03-4e4b-d951-cef29cae3686"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "           pclass         age       sibsp       parch        fare\n",
            "count  712.000000  579.000000  712.000000  712.000000  712.000000\n",
            "mean     2.307584   29.479568    0.518258    0.372191   31.741836\n",
            "std      0.834926   14.355304    1.094522    0.792341   45.403910\n",
            "min      1.000000    0.420000    0.000000    0.000000    0.000000\n",
            "25%      2.000000   20.000000    0.000000    0.000000    7.895800\n",
            "50%      3.000000   28.000000    0.000000    0.000000   14.454200\n",
            "75%      3.000000   38.000000    1.000000    0.000000   31.275000\n",
            "max      3.000000   74.000000    8.000000    6.000000  512.329200\n",
            "           pclass         age       sibsp       parch        fare\n",
            "count  179.000000  135.000000  179.000000  179.000000  179.000000\n",
            "mean     2.312849   30.640741    0.541899    0.418994   34.043364\n",
            "std      0.842950   15.258427    1.137797    0.859760   64.097184\n",
            "min      1.000000    1.000000    0.000000    0.000000    0.000000\n",
            "25%      2.000000   22.000000    0.000000    0.000000    7.925000\n",
            "50%      3.000000   29.000000    0.000000    0.000000   14.500000\n",
            "75%      3.000000   39.000000    1.000000    0.000000   30.285400\n",
            "max      3.000000   80.000000    8.000000    5.000000  512.329200\n",
            "           target\n",
            "count  712.000000\n",
            "mean     0.383427\n",
            "std      0.486563\n",
            "min      0.000000\n",
            "25%      0.000000\n",
            "50%      0.000000\n",
            "75%      1.000000\n",
            "max      1.000000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# object, category 데이터도 추가 확인\n",
        "\n",
        "print(x_train.describe(include='object'))\n",
        "print(x_test.describe(include='object'))\n",
        "print(x_train.describe(include='category'))\n",
        "print(x_test.describe(include='category'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OpFcRXdi65DV",
        "outputId": "83208bfb-bc31-4333-b6d2-77e1590dc873"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "         sex embarked  who  embark_town alive\n",
            "count    712      710  712          710   712\n",
            "unique     2        3    3            3     2\n",
            "top     male        S  man  Southampton    no\n",
            "freq     469      518  432          518   439\n",
            "         sex embarked  who  embark_town alive\n",
            "count    179      179  179          179   179\n",
            "unique     2        3    3            3     2\n",
            "top     male        S  man  Southampton    no\n",
            "freq     108      126  105          126   110\n",
            "        class deck\n",
            "count     712  164\n",
            "unique      3    7\n",
            "top     Third    C\n",
            "freq      391   47\n",
            "        class deck\n",
            "count     179   39\n",
            "unique      3    7\n",
            "top     Third    C\n",
            "freq      100   12\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# y데이터 구체적으로 살펴보기\n",
        "print(y_train.head())\n",
        "print(y_train.value_counts())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eXpmpcyd7LyF",
        "outputId": "d42f88c3-0c57-49a4-f011-f67f8e137871"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     target\n",
            "3         1\n",
            "517       0\n",
            "861       0\n",
            "487       0\n",
            "58        1\n",
            "target\n",
            "0         439\n",
            "1         273\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3) 데이터 전처리 및 분리\n",
        "1) 결측치, 2) 이상치, 3) 변수 처리하기"
      ],
      "metadata": {
        "id": "8OwiHMzC7bsu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 결측치 확인\n",
        "print(x_train.isnull().sum())\n",
        "print(x_test.isnull().sum())\n",
        "print(y_train.isnull().sum())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FlKaau437iar",
        "outputId": "6e12d2ee-73b2-4548-e994-6559dca01114"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "pclass           0\n",
            "sex              0\n",
            "age            133\n",
            "sibsp            0\n",
            "parch            0\n",
            "fare             0\n",
            "embarked         2\n",
            "class            0\n",
            "who              0\n",
            "adult_male       0\n",
            "deck           548\n",
            "embark_town      2\n",
            "alive            0\n",
            "alone            0\n",
            "dtype: int64\n",
            "pclass           0\n",
            "sex              0\n",
            "age             44\n",
            "sibsp            0\n",
            "parch            0\n",
            "fare             0\n",
            "embarked         0\n",
            "class            0\n",
            "who              0\n",
            "adult_male       0\n",
            "deck           140\n",
            "embark_town      0\n",
            "alive            0\n",
            "alone            0\n",
            "dtype: int64\n",
            "target    0\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 결측치 제거\n",
        "# df = df.dropna()\n",
        "# print(df)\n",
        "\n",
        "# 참고사항\n",
        "# print(df.dropna().shape) # 행 기준으로 삭제\n",
        "\n",
        "# ★주의사항\n",
        "# x_train의 행을 제거해야 하는 경우, 그에 해당하는 y_train 행도 제거해야 합니다.\n",
        "# 해결방법 : train = pd.concat([x_train, y_train], axis=1)\n",
        "# 위와 같이 데이터를 결합한 후에 행을 제거하고 다시 데이터 분리를 수행하면 됩니다.\n",
        "# (만약 원데이터가 x_train/y_train이 결합된 형태로 주어진다면 전처리를 모두 수행한 후에 분리하셔도 됩니다)"
      ],
      "metadata": {
        "id": "wqsAVXn99zL8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 결측치 대체\n",
        "# x_train(712,14) : age(133), embarked(2), deck(548), embark_town(2)\n",
        "# x_test(179,14) : age(44), deck(140)\n",
        "\n",
        "# 변수 제거\n",
        "# (중복) class\n",
        "# (중복) embark_town\n",
        "# (중복) alive\n",
        "# (결측치 다수) deck"
      ],
      "metadata": {
        "id": "gxiaQZP792vP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 중복변수 제거\n",
        "x_train = x_train.drop(['class', 'embark_town', 'alive', 'deck'], axis=1)\n",
        "x_test = x_test.drop(['class', 'embark_town', 'alive', 'deck'], axis=1)"
      ],
      "metadata": {
        "id": "toN556Uj-CMB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 변수제거 확인\n",
        "print(x_train.info())\n",
        "print(x_test.info())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UnQCf91G-D7Q",
        "outputId": "ec82530c-6ca6-4e2b-ace6-7be8175baebb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 712 entries, 3 to 608\n",
            "Data columns (total 10 columns):\n",
            " #   Column      Non-Null Count  Dtype  \n",
            "---  ------      --------------  -----  \n",
            " 0   pclass      712 non-null    int64  \n",
            " 1   sex         712 non-null    object \n",
            " 2   age         579 non-null    float64\n",
            " 3   sibsp       712 non-null    int64  \n",
            " 4   parch       712 non-null    int64  \n",
            " 5   fare        712 non-null    float64\n",
            " 6   embarked    710 non-null    object \n",
            " 7   who         712 non-null    object \n",
            " 8   adult_male  712 non-null    bool   \n",
            " 9   alone       712 non-null    bool   \n",
            "dtypes: bool(2), float64(2), int64(3), object(3)\n",
            "memory usage: 51.5+ KB\n",
            "None\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 179 entries, 800 to 410\n",
            "Data columns (total 10 columns):\n",
            " #   Column      Non-Null Count  Dtype  \n",
            "---  ------      --------------  -----  \n",
            " 0   pclass      179 non-null    int64  \n",
            " 1   sex         179 non-null    object \n",
            " 2   age         135 non-null    float64\n",
            " 3   sibsp       179 non-null    int64  \n",
            " 4   parch       179 non-null    int64  \n",
            " 5   fare        179 non-null    float64\n",
            " 6   embarked    179 non-null    object \n",
            " 7   who         179 non-null    object \n",
            " 8   adult_male  179 non-null    bool   \n",
            " 9   alone       179 non-null    bool   \n",
            "dtypes: bool(2), float64(2), int64(3), object(3)\n",
            "memory usage: 12.9+ KB\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 결측치 대체\n",
        "# x_train(712,14) : age(133), embarked(2)\n",
        "# x_test(179,14) : age(44)\n",
        "# age 변수\n",
        "med_age = x_train['age'].median()\n",
        "x_train['age'] = x_train['age'].fillna(med_age)\n",
        "x_test['age'] = x_test['age'].fillna(med_age) # train data의 중앙값으로\n",
        "# embarked\n",
        "mode_et = x_train['embarked'].mode()\n",
        "x_train['embarked'] = x_train['embarked'].fillna(mode_et[0]) # 최빈값 [0] 주의"
      ],
      "metadata": {
        "id": "dmgcrQah-Gfm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 결측치 대체 여부 확인\n",
        "print(x_train.isnull().sum())\n",
        "print(x_test.isnull().sum())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WaIqZQPP-Iac",
        "outputId": "60b2a9a1-1bbf-4c16-9b4b-8514432d633a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "pclass        0\n",
            "sex           0\n",
            "age           0\n",
            "sibsp         0\n",
            "parch         0\n",
            "fare          0\n",
            "embarked      0\n",
            "who           0\n",
            "adult_male    0\n",
            "alone         0\n",
            "dtype: int64\n",
            "pclass        0\n",
            "sex           0\n",
            "age           0\n",
            "sibsp         0\n",
            "parch         0\n",
            "fare          0\n",
            "embarked      0\n",
            "who           0\n",
            "adult_male    0\n",
            "alone         0\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 변수처리 (원핫인코딩)\n",
        "x_train = pd.get_dummies(x_train)\n",
        "x_test = pd.get_dummies(x_test)\n",
        "print(x_train.info())\n",
        "print(x_test.info())\n",
        "# advanced 버전 사용\n",
        "x_train_ad = x_train.copy()\n",
        "x_test_ad = x_test.copy()\n",
        "y_train_ad = y_train.copy()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v-JapumR-Mhp",
        "outputId": "f440cbef-84c3-43bb-9341-8287148fcdc2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 712 entries, 3 to 608\n",
            "Data columns (total 15 columns):\n",
            " #   Column      Non-Null Count  Dtype  \n",
            "---  ------      --------------  -----  \n",
            " 0   pclass      712 non-null    int64  \n",
            " 1   age         712 non-null    float64\n",
            " 2   sibsp       712 non-null    int64  \n",
            " 3   parch       712 non-null    int64  \n",
            " 4   fare        712 non-null    float64\n",
            " 5   adult_male  712 non-null    bool   \n",
            " 6   alone       712 non-null    bool   \n",
            " 7   sex_female  712 non-null    uint8  \n",
            " 8   sex_male    712 non-null    uint8  \n",
            " 9   embarked_C  712 non-null    uint8  \n",
            " 10  embarked_Q  712 non-null    uint8  \n",
            " 11  embarked_S  712 non-null    uint8  \n",
            " 12  who_child   712 non-null    uint8  \n",
            " 13  who_man     712 non-null    uint8  \n",
            " 14  who_woman   712 non-null    uint8  \n",
            "dtypes: bool(2), float64(2), int64(3), uint8(8)\n",
            "memory usage: 40.3 KB\n",
            "None\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 179 entries, 800 to 410\n",
            "Data columns (total 15 columns):\n",
            " #   Column      Non-Null Count  Dtype  \n",
            "---  ------      --------------  -----  \n",
            " 0   pclass      179 non-null    int64  \n",
            " 1   age         179 non-null    float64\n",
            " 2   sibsp       179 non-null    int64  \n",
            " 3   parch       179 non-null    int64  \n",
            " 4   fare        179 non-null    float64\n",
            " 5   adult_male  179 non-null    bool   \n",
            " 6   alone       179 non-null    bool   \n",
            " 7   sex_female  179 non-null    uint8  \n",
            " 8   sex_male    179 non-null    uint8  \n",
            " 9   embarked_C  179 non-null    uint8  \n",
            " 10  embarked_Q  179 non-null    uint8  \n",
            " 11  embarked_S  179 non-null    uint8  \n",
            " 12  who_child   179 non-null    uint8  \n",
            " 13  who_man     179 non-null    uint8  \n",
            " 14  who_woman   179 non-null    uint8  \n",
            "dtypes: bool(2), float64(2), int64(3), uint8(8)\n",
            "memory usage: 10.1 KB\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# (참고사항)원핫인코딩 후 변수의 수가 다른 경우\n",
        "# => x_test의 변수의 수가 x_train 보다 많은 경우 (혹은 그 반대인 경우)\n",
        "# 원핫인코딩 후 Feature 수가 다를 경우\n",
        "# x_train = pd.get_dummies(x_train)\n",
        "# x_test = pd.get_dummies(x_test)\n",
        "# x_train.info()\n",
        "# x_test.info()\n",
        "# 해결방법(x_test의 변수가 수가 더 많은 경우의 코드)\n",
        "# x_train = x_train.reindex(columns = x_test.columns, fill_value=0)\n",
        "# x_train.info()"
      ],
      "metadata": {
        "id": "-XPgGGlx-O7L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import sklearn.model_selection\n",
        "print(help(sklearn.model_selection.train_test_split))"
      ],
      "metadata": {
        "id": "XElwFvn8AIJA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 데이터를 훈련 세트와 검증용 세트로 분할 (80% 훈련, 20% 검증용)\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train['target'], test_size=0.2, stratify=y_train['target'], random_state=2023)\n",
        "\n",
        "print(x_train.shape)\n",
        "print(x_val.shape)\n",
        "print(y_train.shape)\n",
        "print(y_val.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BEeTBnCE_2wt",
        "outputId": "8fe103ea-84d9-41bd-be47-473b0d28e3b3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(569, 15)\n",
            "(143, 15)\n",
            "(569,)\n",
            "(143,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4) 모델링 및 성능평가"
      ],
      "metadata": {
        "id": "z6588bI1CLm9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 랜덤포레스트 모델 사용\n",
        "\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "model = RandomForestClassifier(random_state=2023)\n",
        "model.fit(x_train, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 75
        },
        "id": "tH7seZdOCOXg",
        "outputId": "2822f951-91d1-493d-8de9-18b5bc0b3ae3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomForestClassifier(random_state=2023)"
            ],
            "text/html": [
              "<style>#sk-container-id-4 {color: black;background-color: white;}#sk-container-id-4 pre{padding: 0;}#sk-container-id-4 div.sk-toggleable {background-color: white;}#sk-container-id-4 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-4 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-4 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-4 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-4 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-4 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-4 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-4 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-4 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-4 div.sk-item {position: relative;z-index: 1;}#sk-container-id-4 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-4 div.sk-item::before, #sk-container-id-4 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-4 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-4 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-4 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-4 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-4 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-4 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-4 div.sk-label-container {text-align: center;}#sk-container-id-4 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-4 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(random_state=2023)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" checked><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(random_state=2023)</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 108
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 모델을 사용하여 테스트 데이터 예측\n",
        "y_pred = model.predict(x_val)"
      ],
      "metadata": {
        "id": "jN9nnkySEiLb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import sklearn.metrics\n",
        "print(sklearn.metrics.__all__)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l36tVHTQEzhd",
        "outputId": "b4e9e9eb-1c36-413f-db2f-8590e9bd4b4c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['accuracy_score', 'adjusted_mutual_info_score', 'adjusted_rand_score', 'auc', 'average_precision_score', 'balanced_accuracy_score', 'calinski_harabasz_score', 'check_scoring', 'class_likelihood_ratios', 'classification_report', 'cluster', 'cohen_kappa_score', 'completeness_score', 'ConfusionMatrixDisplay', 'confusion_matrix', 'consensus_score', 'coverage_error', 'd2_tweedie_score', 'd2_absolute_error_score', 'd2_pinball_score', 'dcg_score', 'davies_bouldin_score', 'DetCurveDisplay', 'det_curve', 'DistanceMetric', 'euclidean_distances', 'explained_variance_score', 'f1_score', 'fbeta_score', 'fowlkes_mallows_score', 'get_scorer', 'hamming_loss', 'hinge_loss', 'homogeneity_completeness_v_measure', 'homogeneity_score', 'jaccard_score', 'label_ranking_average_precision_score', 'label_ranking_loss', 'log_loss', 'make_scorer', 'nan_euclidean_distances', 'matthews_corrcoef', 'max_error', 'mean_absolute_error', 'mean_squared_error', 'mean_squared_log_error', 'mean_pinball_loss', 'mean_poisson_deviance', 'mean_gamma_deviance', 'mean_tweedie_deviance', 'median_absolute_error', 'mean_absolute_percentage_error', 'multilabel_confusion_matrix', 'mutual_info_score', 'ndcg_score', 'normalized_mutual_info_score', 'pair_confusion_matrix', 'pairwise_distances', 'pairwise_distances_argmin', 'pairwise_distances_argmin_min', 'pairwise_distances_chunked', 'pairwise_kernels', 'PrecisionRecallDisplay', 'precision_recall_curve', 'precision_recall_fscore_support', 'precision_score', 'PredictionErrorDisplay', 'r2_score', 'rand_score', 'recall_score', 'RocCurveDisplay', 'roc_auc_score', 'roc_curve', 'SCORERS', 'get_scorer_names', 'silhouette_samples', 'silhouette_score', 'top_k_accuracy_score', 'v_measure_score', 'zero_one_loss', 'brier_score_loss']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 모델 성능평가 (정확도, f1 score, 민감도, 특이도 등)\n",
        "\n",
        "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score, recall_score, precision_score\n",
        "acc = accuracy_score(y_val, y_pred)\n",
        "f1 = f1_score(y_val, y_pred)\n",
        "auc = roc_auc_score(y_val, y_pred)"
      ],
      "metadata": {
        "id": "Qap3WLusEpPx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(acc)\n",
        "print(f1)\n",
        "print(auc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b1UxNlP4FTlC",
        "outputId": "d3420af3-5c22-426c-b62f-fa6abdec422c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.8531468531468531\n",
            "0.8108108108108109\n",
            "0.8465909090909092\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 실제 test셋으로 성능평가를 한다면?\n",
        "\n",
        "# 모델을 사용하여 테스트 데이터 예측\n",
        "y_pred_f = model.predict(x_test)\n",
        "\n",
        "# 모델 성능 평가 (정확도, F1 score, AUC)\n",
        "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score\n",
        "\n",
        "acc_f = accuracy_score(y_test, y_pred_f) # (실제값, 예측값)\n",
        "f1_f = f1_score(y_test, y_pred_f) # (실제값, 예측값)\n",
        "auc_f = roc_auc_score(y_test, y_pred_f) # (실제값, 예측값)\n",
        "print(acc_f) # 정확도(Accuracy)\n",
        "print(f1_f) # f1 score\n",
        "print(auc_f) # AUC"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BIp1_q72FbTX",
        "outputId": "e2e5febb-5975-47a1-f4d4-d921e499982d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.7821229050279329\n",
            "0.7153284671532847\n",
            "0.7687088274044797\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Advanced 버전"
      ],
      "metadata": {
        "id": "-TY2nW8DFt2q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(help(sklearn.ensemble.RandomForestClassifier))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l4pRQ0feGGIh",
        "outputId": "ead51f68-774e-4772-f40a-047d524cc117"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Help on class RandomForestClassifier in module sklearn.ensemble._forest:\n",
            "\n",
            "class RandomForestClassifier(ForestClassifier)\n",
            " |  RandomForestClassifier(n_estimators=100, *, criterion='gini', max_depth=None, min_samples_split=2, min_samples_leaf=1, min_weight_fraction_leaf=0.0, max_features='sqrt', max_leaf_nodes=None, min_impurity_decrease=0.0, bootstrap=True, oob_score=False, n_jobs=None, random_state=None, verbose=0, warm_start=False, class_weight=None, ccp_alpha=0.0, max_samples=None)\n",
            " |  \n",
            " |  A random forest classifier.\n",
            " |  \n",
            " |  A random forest is a meta estimator that fits a number of decision tree\n",
            " |  classifiers on various sub-samples of the dataset and uses averaging to\n",
            " |  improve the predictive accuracy and control over-fitting.\n",
            " |  The sub-sample size is controlled with the `max_samples` parameter if\n",
            " |  `bootstrap=True` (default), otherwise the whole dataset is used to build\n",
            " |  each tree.\n",
            " |  \n",
            " |  Read more in the :ref:`User Guide <forest>`.\n",
            " |  \n",
            " |  Parameters\n",
            " |  ----------\n",
            " |  n_estimators : int, default=100\n",
            " |      The number of trees in the forest.\n",
            " |  \n",
            " |      .. versionchanged:: 0.22\n",
            " |         The default value of ``n_estimators`` changed from 10 to 100\n",
            " |         in 0.22.\n",
            " |  \n",
            " |  criterion : {\"gini\", \"entropy\", \"log_loss\"}, default=\"gini\"\n",
            " |      The function to measure the quality of a split. Supported criteria are\n",
            " |      \"gini\" for the Gini impurity and \"log_loss\" and \"entropy\" both for the\n",
            " |      Shannon information gain, see :ref:`tree_mathematical_formulation`.\n",
            " |      Note: This parameter is tree-specific.\n",
            " |  \n",
            " |  max_depth : int, default=None\n",
            " |      The maximum depth of the tree. If None, then nodes are expanded until\n",
            " |      all leaves are pure or until all leaves contain less than\n",
            " |      min_samples_split samples.\n",
            " |  \n",
            " |  min_samples_split : int or float, default=2\n",
            " |      The minimum number of samples required to split an internal node:\n",
            " |  \n",
            " |      - If int, then consider `min_samples_split` as the minimum number.\n",
            " |      - If float, then `min_samples_split` is a fraction and\n",
            " |        `ceil(min_samples_split * n_samples)` are the minimum\n",
            " |        number of samples for each split.\n",
            " |  \n",
            " |      .. versionchanged:: 0.18\n",
            " |         Added float values for fractions.\n",
            " |  \n",
            " |  min_samples_leaf : int or float, default=1\n",
            " |      The minimum number of samples required to be at a leaf node.\n",
            " |      A split point at any depth will only be considered if it leaves at\n",
            " |      least ``min_samples_leaf`` training samples in each of the left and\n",
            " |      right branches.  This may have the effect of smoothing the model,\n",
            " |      especially in regression.\n",
            " |  \n",
            " |      - If int, then consider `min_samples_leaf` as the minimum number.\n",
            " |      - If float, then `min_samples_leaf` is a fraction and\n",
            " |        `ceil(min_samples_leaf * n_samples)` are the minimum\n",
            " |        number of samples for each node.\n",
            " |  \n",
            " |      .. versionchanged:: 0.18\n",
            " |         Added float values for fractions.\n",
            " |  \n",
            " |  min_weight_fraction_leaf : float, default=0.0\n",
            " |      The minimum weighted fraction of the sum total of weights (of all\n",
            " |      the input samples) required to be at a leaf node. Samples have\n",
            " |      equal weight when sample_weight is not provided.\n",
            " |  \n",
            " |  max_features : {\"sqrt\", \"log2\", None}, int or float, default=\"sqrt\"\n",
            " |      The number of features to consider when looking for the best split:\n",
            " |  \n",
            " |      - If int, then consider `max_features` features at each split.\n",
            " |      - If float, then `max_features` is a fraction and\n",
            " |        `max(1, int(max_features * n_features_in_))` features are considered at each\n",
            " |        split.\n",
            " |      - If \"auto\", then `max_features=sqrt(n_features)`.\n",
            " |      - If \"sqrt\", then `max_features=sqrt(n_features)`.\n",
            " |      - If \"log2\", then `max_features=log2(n_features)`.\n",
            " |      - If None, then `max_features=n_features`.\n",
            " |  \n",
            " |      .. versionchanged:: 1.1\n",
            " |          The default of `max_features` changed from `\"auto\"` to `\"sqrt\"`.\n",
            " |  \n",
            " |      .. deprecated:: 1.1\n",
            " |          The `\"auto\"` option was deprecated in 1.1 and will be removed\n",
            " |          in 1.3.\n",
            " |  \n",
            " |      Note: the search for a split does not stop until at least one\n",
            " |      valid partition of the node samples is found, even if it requires to\n",
            " |      effectively inspect more than ``max_features`` features.\n",
            " |  \n",
            " |  max_leaf_nodes : int, default=None\n",
            " |      Grow trees with ``max_leaf_nodes`` in best-first fashion.\n",
            " |      Best nodes are defined as relative reduction in impurity.\n",
            " |      If None then unlimited number of leaf nodes.\n",
            " |  \n",
            " |  min_impurity_decrease : float, default=0.0\n",
            " |      A node will be split if this split induces a decrease of the impurity\n",
            " |      greater than or equal to this value.\n",
            " |  \n",
            " |      The weighted impurity decrease equation is the following::\n",
            " |  \n",
            " |          N_t / N * (impurity - N_t_R / N_t * right_impurity\n",
            " |                              - N_t_L / N_t * left_impurity)\n",
            " |  \n",
            " |      where ``N`` is the total number of samples, ``N_t`` is the number of\n",
            " |      samples at the current node, ``N_t_L`` is the number of samples in the\n",
            " |      left child, and ``N_t_R`` is the number of samples in the right child.\n",
            " |  \n",
            " |      ``N``, ``N_t``, ``N_t_R`` and ``N_t_L`` all refer to the weighted sum,\n",
            " |      if ``sample_weight`` is passed.\n",
            " |  \n",
            " |      .. versionadded:: 0.19\n",
            " |  \n",
            " |  bootstrap : bool, default=True\n",
            " |      Whether bootstrap samples are used when building trees. If False, the\n",
            " |      whole dataset is used to build each tree.\n",
            " |  \n",
            " |  oob_score : bool, default=False\n",
            " |      Whether to use out-of-bag samples to estimate the generalization score.\n",
            " |      Only available if bootstrap=True.\n",
            " |  \n",
            " |  n_jobs : int, default=None\n",
            " |      The number of jobs to run in parallel. :meth:`fit`, :meth:`predict`,\n",
            " |      :meth:`decision_path` and :meth:`apply` are all parallelized over the\n",
            " |      trees. ``None`` means 1 unless in a :obj:`joblib.parallel_backend`\n",
            " |      context. ``-1`` means using all processors. See :term:`Glossary\n",
            " |      <n_jobs>` for more details.\n",
            " |  \n",
            " |  random_state : int, RandomState instance or None, default=None\n",
            " |      Controls both the randomness of the bootstrapping of the samples used\n",
            " |      when building trees (if ``bootstrap=True``) and the sampling of the\n",
            " |      features to consider when looking for the best split at each node\n",
            " |      (if ``max_features < n_features``).\n",
            " |      See :term:`Glossary <random_state>` for details.\n",
            " |  \n",
            " |  verbose : int, default=0\n",
            " |      Controls the verbosity when fitting and predicting.\n",
            " |  \n",
            " |  warm_start : bool, default=False\n",
            " |      When set to ``True``, reuse the solution of the previous call to fit\n",
            " |      and add more estimators to the ensemble, otherwise, just fit a whole\n",
            " |      new forest. See :term:`Glossary <warm_start>` and\n",
            " |      :ref:`gradient_boosting_warm_start` for details.\n",
            " |  \n",
            " |  class_weight : {\"balanced\", \"balanced_subsample\"}, dict or list of dicts,             default=None\n",
            " |      Weights associated with classes in the form ``{class_label: weight}``.\n",
            " |      If not given, all classes are supposed to have weight one. For\n",
            " |      multi-output problems, a list of dicts can be provided in the same\n",
            " |      order as the columns of y.\n",
            " |  \n",
            " |      Note that for multioutput (including multilabel) weights should be\n",
            " |      defined for each class of every column in its own dict. For example,\n",
            " |      for four-class multilabel classification weights should be\n",
            " |      [{0: 1, 1: 1}, {0: 1, 1: 5}, {0: 1, 1: 1}, {0: 1, 1: 1}] instead of\n",
            " |      [{1:1}, {2:5}, {3:1}, {4:1}].\n",
            " |  \n",
            " |      The \"balanced\" mode uses the values of y to automatically adjust\n",
            " |      weights inversely proportional to class frequencies in the input data\n",
            " |      as ``n_samples / (n_classes * np.bincount(y))``\n",
            " |  \n",
            " |      The \"balanced_subsample\" mode is the same as \"balanced\" except that\n",
            " |      weights are computed based on the bootstrap sample for every tree\n",
            " |      grown.\n",
            " |  \n",
            " |      For multi-output, the weights of each column of y will be multiplied.\n",
            " |  \n",
            " |      Note that these weights will be multiplied with sample_weight (passed\n",
            " |      through the fit method) if sample_weight is specified.\n",
            " |  \n",
            " |  ccp_alpha : non-negative float, default=0.0\n",
            " |      Complexity parameter used for Minimal Cost-Complexity Pruning. The\n",
            " |      subtree with the largest cost complexity that is smaller than\n",
            " |      ``ccp_alpha`` will be chosen. By default, no pruning is performed. See\n",
            " |      :ref:`minimal_cost_complexity_pruning` for details.\n",
            " |  \n",
            " |      .. versionadded:: 0.22\n",
            " |  \n",
            " |  max_samples : int or float, default=None\n",
            " |      If bootstrap is True, the number of samples to draw from X\n",
            " |      to train each base estimator.\n",
            " |  \n",
            " |      - If None (default), then draw `X.shape[0]` samples.\n",
            " |      - If int, then draw `max_samples` samples.\n",
            " |      - If float, then draw `max_samples * X.shape[0]` samples. Thus,\n",
            " |        `max_samples` should be in the interval `(0.0, 1.0]`.\n",
            " |  \n",
            " |      .. versionadded:: 0.22\n",
            " |  \n",
            " |  Attributes\n",
            " |  ----------\n",
            " |  estimator_ : :class:`~sklearn.tree.DecisionTreeClassifier`\n",
            " |      The child estimator template used to create the collection of fitted\n",
            " |      sub-estimators.\n",
            " |  \n",
            " |      .. versionadded:: 1.2\n",
            " |         `base_estimator_` was renamed to `estimator_`.\n",
            " |  \n",
            " |  base_estimator_ : DecisionTreeClassifier\n",
            " |      The child estimator template used to create the collection of fitted\n",
            " |      sub-estimators.\n",
            " |  \n",
            " |      .. deprecated:: 1.2\n",
            " |          `base_estimator_` is deprecated and will be removed in 1.4.\n",
            " |          Use `estimator_` instead.\n",
            " |  \n",
            " |  estimators_ : list of DecisionTreeClassifier\n",
            " |      The collection of fitted sub-estimators.\n",
            " |  \n",
            " |  classes_ : ndarray of shape (n_classes,) or a list of such arrays\n",
            " |      The classes labels (single output problem), or a list of arrays of\n",
            " |      class labels (multi-output problem).\n",
            " |  \n",
            " |  n_classes_ : int or list\n",
            " |      The number of classes (single output problem), or a list containing the\n",
            " |      number of classes for each output (multi-output problem).\n",
            " |  \n",
            " |  n_features_in_ : int\n",
            " |      Number of features seen during :term:`fit`.\n",
            " |  \n",
            " |      .. versionadded:: 0.24\n",
            " |  \n",
            " |  feature_names_in_ : ndarray of shape (`n_features_in_`,)\n",
            " |      Names of features seen during :term:`fit`. Defined only when `X`\n",
            " |      has feature names that are all strings.\n",
            " |  \n",
            " |      .. versionadded:: 1.0\n",
            " |  \n",
            " |  n_outputs_ : int\n",
            " |      The number of outputs when ``fit`` is performed.\n",
            " |  \n",
            " |  feature_importances_ : ndarray of shape (n_features,)\n",
            " |      The impurity-based feature importances.\n",
            " |      The higher, the more important the feature.\n",
            " |      The importance of a feature is computed as the (normalized)\n",
            " |      total reduction of the criterion brought by that feature.  It is also\n",
            " |      known as the Gini importance.\n",
            " |  \n",
            " |      Warning: impurity-based feature importances can be misleading for\n",
            " |      high cardinality features (many unique values). See\n",
            " |      :func:`sklearn.inspection.permutation_importance` as an alternative.\n",
            " |  \n",
            " |  oob_score_ : float\n",
            " |      Score of the training dataset obtained using an out-of-bag estimate.\n",
            " |      This attribute exists only when ``oob_score`` is True.\n",
            " |  \n",
            " |  oob_decision_function_ : ndarray of shape (n_samples, n_classes) or             (n_samples, n_classes, n_outputs)\n",
            " |      Decision function computed with out-of-bag estimate on the training\n",
            " |      set. If n_estimators is small it might be possible that a data point\n",
            " |      was never left out during the bootstrap. In this case,\n",
            " |      `oob_decision_function_` might contain NaN. This attribute exists\n",
            " |      only when ``oob_score`` is True.\n",
            " |  \n",
            " |  See Also\n",
            " |  --------\n",
            " |  sklearn.tree.DecisionTreeClassifier : A decision tree classifier.\n",
            " |  sklearn.ensemble.ExtraTreesClassifier : Ensemble of extremely randomized\n",
            " |      tree classifiers.\n",
            " |  \n",
            " |  Notes\n",
            " |  -----\n",
            " |  The default values for the parameters controlling the size of the trees\n",
            " |  (e.g. ``max_depth``, ``min_samples_leaf``, etc.) lead to fully grown and\n",
            " |  unpruned trees which can potentially be very large on some data sets. To\n",
            " |  reduce memory consumption, the complexity and size of the trees should be\n",
            " |  controlled by setting those parameter values.\n",
            " |  \n",
            " |  The features are always randomly permuted at each split. Therefore,\n",
            " |  the best found split may vary, even with the same training data,\n",
            " |  ``max_features=n_features`` and ``bootstrap=False``, if the improvement\n",
            " |  of the criterion is identical for several splits enumerated during the\n",
            " |  search of the best split. To obtain a deterministic behaviour during\n",
            " |  fitting, ``random_state`` has to be fixed.\n",
            " |  \n",
            " |  References\n",
            " |  ----------\n",
            " |  .. [1] L. Breiman, \"Random Forests\", Machine Learning, 45(1), 5-32, 2001.\n",
            " |  \n",
            " |  Examples\n",
            " |  --------\n",
            " |  >>> from sklearn.ensemble import RandomForestClassifier\n",
            " |  >>> from sklearn.datasets import make_classification\n",
            " |  >>> X, y = make_classification(n_samples=1000, n_features=4,\n",
            " |  ...                            n_informative=2, n_redundant=0,\n",
            " |  ...                            random_state=0, shuffle=False)\n",
            " |  >>> clf = RandomForestClassifier(max_depth=2, random_state=0)\n",
            " |  >>> clf.fit(X, y)\n",
            " |  RandomForestClassifier(...)\n",
            " |  >>> print(clf.predict([[0, 0, 0, 0]]))\n",
            " |  [1]\n",
            " |  \n",
            " |  Method resolution order:\n",
            " |      RandomForestClassifier\n",
            " |      ForestClassifier\n",
            " |      sklearn.base.ClassifierMixin\n",
            " |      BaseForest\n",
            " |      sklearn.base.MultiOutputMixin\n",
            " |      sklearn.ensemble._base.BaseEnsemble\n",
            " |      sklearn.base.MetaEstimatorMixin\n",
            " |      sklearn.base.BaseEstimator\n",
            " |      builtins.object\n",
            " |  \n",
            " |  Methods defined here:\n",
            " |  \n",
            " |  __init__(self, n_estimators=100, *, criterion='gini', max_depth=None, min_samples_split=2, min_samples_leaf=1, min_weight_fraction_leaf=0.0, max_features='sqrt', max_leaf_nodes=None, min_impurity_decrease=0.0, bootstrap=True, oob_score=False, n_jobs=None, random_state=None, verbose=0, warm_start=False, class_weight=None, ccp_alpha=0.0, max_samples=None)\n",
            " |      Initialize self.  See help(type(self)) for accurate signature.\n",
            " |  \n",
            " |  ----------------------------------------------------------------------\n",
            " |  Data and other attributes defined here:\n",
            " |  \n",
            " |  __abstractmethods__ = frozenset()\n",
            " |  \n",
            " |  __annotations__ = {'_parameter_constraints': <class 'dict'>}\n",
            " |  \n",
            " |  ----------------------------------------------------------------------\n",
            " |  Methods inherited from ForestClassifier:\n",
            " |  \n",
            " |  predict(self, X)\n",
            " |      Predict class for X.\n",
            " |      \n",
            " |      The predicted class of an input sample is a vote by the trees in\n",
            " |      the forest, weighted by their probability estimates. That is,\n",
            " |      the predicted class is the one with highest mean probability\n",
            " |      estimate across the trees.\n",
            " |      \n",
            " |      Parameters\n",
            " |      ----------\n",
            " |      X : {array-like, sparse matrix} of shape (n_samples, n_features)\n",
            " |          The input samples. Internally, its dtype will be converted to\n",
            " |          ``dtype=np.float32``. If a sparse matrix is provided, it will be\n",
            " |          converted into a sparse ``csr_matrix``.\n",
            " |      \n",
            " |      Returns\n",
            " |      -------\n",
            " |      y : ndarray of shape (n_samples,) or (n_samples, n_outputs)\n",
            " |          The predicted classes.\n",
            " |  \n",
            " |  predict_log_proba(self, X)\n",
            " |      Predict class log-probabilities for X.\n",
            " |      \n",
            " |      The predicted class log-probabilities of an input sample is computed as\n",
            " |      the log of the mean predicted class probabilities of the trees in the\n",
            " |      forest.\n",
            " |      \n",
            " |      Parameters\n",
            " |      ----------\n",
            " |      X : {array-like, sparse matrix} of shape (n_samples, n_features)\n",
            " |          The input samples. Internally, its dtype will be converted to\n",
            " |          ``dtype=np.float32``. If a sparse matrix is provided, it will be\n",
            " |          converted into a sparse ``csr_matrix``.\n",
            " |      \n",
            " |      Returns\n",
            " |      -------\n",
            " |      p : ndarray of shape (n_samples, n_classes), or a list of such arrays\n",
            " |          The class probabilities of the input samples. The order of the\n",
            " |          classes corresponds to that in the attribute :term:`classes_`.\n",
            " |  \n",
            " |  predict_proba(self, X)\n",
            " |      Predict class probabilities for X.\n",
            " |      \n",
            " |      The predicted class probabilities of an input sample are computed as\n",
            " |      the mean predicted class probabilities of the trees in the forest.\n",
            " |      The class probability of a single tree is the fraction of samples of\n",
            " |      the same class in a leaf.\n",
            " |      \n",
            " |      Parameters\n",
            " |      ----------\n",
            " |      X : {array-like, sparse matrix} of shape (n_samples, n_features)\n",
            " |          The input samples. Internally, its dtype will be converted to\n",
            " |          ``dtype=np.float32``. If a sparse matrix is provided, it will be\n",
            " |          converted into a sparse ``csr_matrix``.\n",
            " |      \n",
            " |      Returns\n",
            " |      -------\n",
            " |      p : ndarray of shape (n_samples, n_classes), or a list of such arrays\n",
            " |          The class probabilities of the input samples. The order of the\n",
            " |          classes corresponds to that in the attribute :term:`classes_`.\n",
            " |  \n",
            " |  ----------------------------------------------------------------------\n",
            " |  Methods inherited from sklearn.base.ClassifierMixin:\n",
            " |  \n",
            " |  score(self, X, y, sample_weight=None)\n",
            " |      Return the mean accuracy on the given test data and labels.\n",
            " |      \n",
            " |      In multi-label classification, this is the subset accuracy\n",
            " |      which is a harsh metric since you require for each sample that\n",
            " |      each label set be correctly predicted.\n",
            " |      \n",
            " |      Parameters\n",
            " |      ----------\n",
            " |      X : array-like of shape (n_samples, n_features)\n",
            " |          Test samples.\n",
            " |      \n",
            " |      y : array-like of shape (n_samples,) or (n_samples, n_outputs)\n",
            " |          True labels for `X`.\n",
            " |      \n",
            " |      sample_weight : array-like of shape (n_samples,), default=None\n",
            " |          Sample weights.\n",
            " |      \n",
            " |      Returns\n",
            " |      -------\n",
            " |      score : float\n",
            " |          Mean accuracy of ``self.predict(X)`` w.r.t. `y`.\n",
            " |  \n",
            " |  ----------------------------------------------------------------------\n",
            " |  Data descriptors inherited from sklearn.base.ClassifierMixin:\n",
            " |  \n",
            " |  __dict__\n",
            " |      dictionary for instance variables (if defined)\n",
            " |  \n",
            " |  __weakref__\n",
            " |      list of weak references to the object (if defined)\n",
            " |  \n",
            " |  ----------------------------------------------------------------------\n",
            " |  Methods inherited from BaseForest:\n",
            " |  \n",
            " |  apply(self, X)\n",
            " |      Apply trees in the forest to X, return leaf indices.\n",
            " |      \n",
            " |      Parameters\n",
            " |      ----------\n",
            " |      X : {array-like, sparse matrix} of shape (n_samples, n_features)\n",
            " |          The input samples. Internally, its dtype will be converted to\n",
            " |          ``dtype=np.float32``. If a sparse matrix is provided, it will be\n",
            " |          converted into a sparse ``csr_matrix``.\n",
            " |      \n",
            " |      Returns\n",
            " |      -------\n",
            " |      X_leaves : ndarray of shape (n_samples, n_estimators)\n",
            " |          For each datapoint x in X and for each tree in the forest,\n",
            " |          return the index of the leaf x ends up in.\n",
            " |  \n",
            " |  decision_path(self, X)\n",
            " |      Return the decision path in the forest.\n",
            " |      \n",
            " |      .. versionadded:: 0.18\n",
            " |      \n",
            " |      Parameters\n",
            " |      ----------\n",
            " |      X : {array-like, sparse matrix} of shape (n_samples, n_features)\n",
            " |          The input samples. Internally, its dtype will be converted to\n",
            " |          ``dtype=np.float32``. If a sparse matrix is provided, it will be\n",
            " |          converted into a sparse ``csr_matrix``.\n",
            " |      \n",
            " |      Returns\n",
            " |      -------\n",
            " |      indicator : sparse matrix of shape (n_samples, n_nodes)\n",
            " |          Return a node indicator matrix where non zero elements indicates\n",
            " |          that the samples goes through the nodes. The matrix is of CSR\n",
            " |          format.\n",
            " |      \n",
            " |      n_nodes_ptr : ndarray of shape (n_estimators + 1,)\n",
            " |          The columns from indicator[n_nodes_ptr[i]:n_nodes_ptr[i+1]]\n",
            " |          gives the indicator value for the i-th estimator.\n",
            " |  \n",
            " |  fit(self, X, y, sample_weight=None)\n",
            " |      Build a forest of trees from the training set (X, y).\n",
            " |      \n",
            " |      Parameters\n",
            " |      ----------\n",
            " |      X : {array-like, sparse matrix} of shape (n_samples, n_features)\n",
            " |          The training input samples. Internally, its dtype will be converted\n",
            " |          to ``dtype=np.float32``. If a sparse matrix is provided, it will be\n",
            " |          converted into a sparse ``csc_matrix``.\n",
            " |      \n",
            " |      y : array-like of shape (n_samples,) or (n_samples, n_outputs)\n",
            " |          The target values (class labels in classification, real numbers in\n",
            " |          regression).\n",
            " |      \n",
            " |      sample_weight : array-like of shape (n_samples,), default=None\n",
            " |          Sample weights. If None, then samples are equally weighted. Splits\n",
            " |          that would create child nodes with net zero or negative weight are\n",
            " |          ignored while searching for a split in each node. In the case of\n",
            " |          classification, splits are also ignored if they would result in any\n",
            " |          single class carrying a negative weight in either child node.\n",
            " |      \n",
            " |      Returns\n",
            " |      -------\n",
            " |      self : object\n",
            " |          Fitted estimator.\n",
            " |  \n",
            " |  ----------------------------------------------------------------------\n",
            " |  Readonly properties inherited from BaseForest:\n",
            " |  \n",
            " |  feature_importances_\n",
            " |      The impurity-based feature importances.\n",
            " |      \n",
            " |      The higher, the more important the feature.\n",
            " |      The importance of a feature is computed as the (normalized)\n",
            " |      total reduction of the criterion brought by that feature.  It is also\n",
            " |      known as the Gini importance.\n",
            " |      \n",
            " |      Warning: impurity-based feature importances can be misleading for\n",
            " |      high cardinality features (many unique values). See\n",
            " |      :func:`sklearn.inspection.permutation_importance` as an alternative.\n",
            " |      \n",
            " |      Returns\n",
            " |      -------\n",
            " |      feature_importances_ : ndarray of shape (n_features,)\n",
            " |          The values of this array sum to 1, unless all trees are single node\n",
            " |          trees consisting of only the root node, in which case it will be an\n",
            " |          array of zeros.\n",
            " |  \n",
            " |  ----------------------------------------------------------------------\n",
            " |  Methods inherited from sklearn.ensemble._base.BaseEnsemble:\n",
            " |  \n",
            " |  __getitem__(self, index)\n",
            " |      Return the index'th estimator in the ensemble.\n",
            " |  \n",
            " |  __iter__(self)\n",
            " |      Return iterator over estimators in the ensemble.\n",
            " |  \n",
            " |  __len__(self)\n",
            " |      Return the number of estimators in the ensemble.\n",
            " |  \n",
            " |  ----------------------------------------------------------------------\n",
            " |  Readonly properties inherited from sklearn.ensemble._base.BaseEnsemble:\n",
            " |  \n",
            " |  base_estimator_\n",
            " |      Estimator used to grow the ensemble.\n",
            " |  \n",
            " |  ----------------------------------------------------------------------\n",
            " |  Methods inherited from sklearn.base.BaseEstimator:\n",
            " |  \n",
            " |  __getstate__(self)\n",
            " |  \n",
            " |  __repr__(self, N_CHAR_MAX=700)\n",
            " |      Return repr(self).\n",
            " |  \n",
            " |  __setstate__(self, state)\n",
            " |  \n",
            " |  get_params(self, deep=True)\n",
            " |      Get parameters for this estimator.\n",
            " |      \n",
            " |      Parameters\n",
            " |      ----------\n",
            " |      deep : bool, default=True\n",
            " |          If True, will return the parameters for this estimator and\n",
            " |          contained subobjects that are estimators.\n",
            " |      \n",
            " |      Returns\n",
            " |      -------\n",
            " |      params : dict\n",
            " |          Parameter names mapped to their values.\n",
            " |  \n",
            " |  set_params(self, **params)\n",
            " |      Set the parameters of this estimator.\n",
            " |      \n",
            " |      The method works on simple estimators as well as on nested objects\n",
            " |      (such as :class:`~sklearn.pipeline.Pipeline`). The latter have\n",
            " |      parameters of the form ``<component>__<parameter>`` so that it's\n",
            " |      possible to update each component of a nested object.\n",
            " |      \n",
            " |      Parameters\n",
            " |      ----------\n",
            " |      **params : dict\n",
            " |          Estimator parameters.\n",
            " |      \n",
            " |      Returns\n",
            " |      -------\n",
            " |      self : estimator instance\n",
            " |          Estimator instance.\n",
            "\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "print(help(sklearn.model_selection.GridSearchCV))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v8PlhuKfG5g_",
        "outputId": "4cd34fcb-4994-4607-8c37-18f2d5cec5ad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Help on class GridSearchCV in module sklearn.model_selection._search:\n",
            "\n",
            "class GridSearchCV(BaseSearchCV)\n",
            " |  GridSearchCV(estimator, param_grid, *, scoring=None, n_jobs=None, refit=True, cv=None, verbose=0, pre_dispatch='2*n_jobs', error_score=nan, return_train_score=False)\n",
            " |  \n",
            " |  Exhaustive search over specified parameter values for an estimator.\n",
            " |  \n",
            " |  Important members are fit, predict.\n",
            " |  \n",
            " |  GridSearchCV implements a \"fit\" and a \"score\" method.\n",
            " |  It also implements \"score_samples\", \"predict\", \"predict_proba\",\n",
            " |  \"decision_function\", \"transform\" and \"inverse_transform\" if they are\n",
            " |  implemented in the estimator used.\n",
            " |  \n",
            " |  The parameters of the estimator used to apply these methods are optimized\n",
            " |  by cross-validated grid-search over a parameter grid.\n",
            " |  \n",
            " |  Read more in the :ref:`User Guide <grid_search>`.\n",
            " |  \n",
            " |  Parameters\n",
            " |  ----------\n",
            " |  estimator : estimator object\n",
            " |      This is assumed to implement the scikit-learn estimator interface.\n",
            " |      Either estimator needs to provide a ``score`` function,\n",
            " |      or ``scoring`` must be passed.\n",
            " |  \n",
            " |  param_grid : dict or list of dictionaries\n",
            " |      Dictionary with parameters names (`str`) as keys and lists of\n",
            " |      parameter settings to try as values, or a list of such\n",
            " |      dictionaries, in which case the grids spanned by each dictionary\n",
            " |      in the list are explored. This enables searching over any sequence\n",
            " |      of parameter settings.\n",
            " |  \n",
            " |  scoring : str, callable, list, tuple or dict, default=None\n",
            " |      Strategy to evaluate the performance of the cross-validated model on\n",
            " |      the test set.\n",
            " |  \n",
            " |      If `scoring` represents a single score, one can use:\n",
            " |  \n",
            " |      - a single string (see :ref:`scoring_parameter`);\n",
            " |      - a callable (see :ref:`scoring`) that returns a single value.\n",
            " |  \n",
            " |      If `scoring` represents multiple scores, one can use:\n",
            " |  \n",
            " |      - a list or tuple of unique strings;\n",
            " |      - a callable returning a dictionary where the keys are the metric\n",
            " |        names and the values are the metric scores;\n",
            " |      - a dictionary with metric names as keys and callables a values.\n",
            " |  \n",
            " |      See :ref:`multimetric_grid_search` for an example.\n",
            " |  \n",
            " |  n_jobs : int, default=None\n",
            " |      Number of jobs to run in parallel.\n",
            " |      ``None`` means 1 unless in a :obj:`joblib.parallel_backend` context.\n",
            " |      ``-1`` means using all processors. See :term:`Glossary <n_jobs>`\n",
            " |      for more details.\n",
            " |  \n",
            " |      .. versionchanged:: v0.20\n",
            " |         `n_jobs` default changed from 1 to None\n",
            " |  \n",
            " |  refit : bool, str, or callable, default=True\n",
            " |      Refit an estimator using the best found parameters on the whole\n",
            " |      dataset.\n",
            " |  \n",
            " |      For multiple metric evaluation, this needs to be a `str` denoting the\n",
            " |      scorer that would be used to find the best parameters for refitting\n",
            " |      the estimator at the end.\n",
            " |  \n",
            " |      Where there are considerations other than maximum score in\n",
            " |      choosing a best estimator, ``refit`` can be set to a function which\n",
            " |      returns the selected ``best_index_`` given ``cv_results_``. In that\n",
            " |      case, the ``best_estimator_`` and ``best_params_`` will be set\n",
            " |      according to the returned ``best_index_`` while the ``best_score_``\n",
            " |      attribute will not be available.\n",
            " |  \n",
            " |      The refitted estimator is made available at the ``best_estimator_``\n",
            " |      attribute and permits using ``predict`` directly on this\n",
            " |      ``GridSearchCV`` instance.\n",
            " |  \n",
            " |      Also for multiple metric evaluation, the attributes ``best_index_``,\n",
            " |      ``best_score_`` and ``best_params_`` will only be available if\n",
            " |      ``refit`` is set and all of them will be determined w.r.t this specific\n",
            " |      scorer.\n",
            " |  \n",
            " |      See ``scoring`` parameter to know more about multiple metric\n",
            " |      evaluation.\n",
            " |  \n",
            " |      See :ref:`sphx_glr_auto_examples_model_selection_plot_grid_search_digits.py`\n",
            " |      to see how to design a custom selection strategy using a callable\n",
            " |      via `refit`.\n",
            " |  \n",
            " |      .. versionchanged:: 0.20\n",
            " |          Support for callable added.\n",
            " |  \n",
            " |  cv : int, cross-validation generator or an iterable, default=None\n",
            " |      Determines the cross-validation splitting strategy.\n",
            " |      Possible inputs for cv are:\n",
            " |  \n",
            " |      - None, to use the default 5-fold cross validation,\n",
            " |      - integer, to specify the number of folds in a `(Stratified)KFold`,\n",
            " |      - :term:`CV splitter`,\n",
            " |      - An iterable yielding (train, test) splits as arrays of indices.\n",
            " |  \n",
            " |      For integer/None inputs, if the estimator is a classifier and ``y`` is\n",
            " |      either binary or multiclass, :class:`StratifiedKFold` is used. In all\n",
            " |      other cases, :class:`KFold` is used. These splitters are instantiated\n",
            " |      with `shuffle=False` so the splits will be the same across calls.\n",
            " |  \n",
            " |      Refer :ref:`User Guide <cross_validation>` for the various\n",
            " |      cross-validation strategies that can be used here.\n",
            " |  \n",
            " |      .. versionchanged:: 0.22\n",
            " |          ``cv`` default value if None changed from 3-fold to 5-fold.\n",
            " |  \n",
            " |  verbose : int\n",
            " |      Controls the verbosity: the higher, the more messages.\n",
            " |  \n",
            " |      - >1 : the computation time for each fold and parameter candidate is\n",
            " |        displayed;\n",
            " |      - >2 : the score is also displayed;\n",
            " |      - >3 : the fold and candidate parameter indexes are also displayed\n",
            " |        together with the starting time of the computation.\n",
            " |  \n",
            " |  pre_dispatch : int, or str, default='2*n_jobs'\n",
            " |      Controls the number of jobs that get dispatched during parallel\n",
            " |      execution. Reducing this number can be useful to avoid an\n",
            " |      explosion of memory consumption when more jobs get dispatched\n",
            " |      than CPUs can process. This parameter can be:\n",
            " |  \n",
            " |          - None, in which case all the jobs are immediately\n",
            " |            created and spawned. Use this for lightweight and\n",
            " |            fast-running jobs, to avoid delays due to on-demand\n",
            " |            spawning of the jobs\n",
            " |  \n",
            " |          - An int, giving the exact number of total jobs that are\n",
            " |            spawned\n",
            " |  \n",
            " |          - A str, giving an expression as a function of n_jobs,\n",
            " |            as in '2*n_jobs'\n",
            " |  \n",
            " |  error_score : 'raise' or numeric, default=np.nan\n",
            " |      Value to assign to the score if an error occurs in estimator fitting.\n",
            " |      If set to 'raise', the error is raised. If a numeric value is given,\n",
            " |      FitFailedWarning is raised. This parameter does not affect the refit\n",
            " |      step, which will always raise the error.\n",
            " |  \n",
            " |  return_train_score : bool, default=False\n",
            " |      If ``False``, the ``cv_results_`` attribute will not include training\n",
            " |      scores.\n",
            " |      Computing training scores is used to get insights on how different\n",
            " |      parameter settings impact the overfitting/underfitting trade-off.\n",
            " |      However computing the scores on the training set can be computationally\n",
            " |      expensive and is not strictly required to select the parameters that\n",
            " |      yield the best generalization performance.\n",
            " |  \n",
            " |      .. versionadded:: 0.19\n",
            " |  \n",
            " |      .. versionchanged:: 0.21\n",
            " |          Default value was changed from ``True`` to ``False``\n",
            " |  \n",
            " |  Attributes\n",
            " |  ----------\n",
            " |  cv_results_ : dict of numpy (masked) ndarrays\n",
            " |      A dict with keys as column headers and values as columns, that can be\n",
            " |      imported into a pandas ``DataFrame``.\n",
            " |  \n",
            " |      For instance the below given table\n",
            " |  \n",
            " |      +------------+-----------+------------+-----------------+---+---------+\n",
            " |      |param_kernel|param_gamma|param_degree|split0_test_score|...|rank_t...|\n",
            " |      +============+===========+============+=================+===+=========+\n",
            " |      |  'poly'    |     --    |      2     |       0.80      |...|    2    |\n",
            " |      +------------+-----------+------------+-----------------+---+---------+\n",
            " |      |  'poly'    |     --    |      3     |       0.70      |...|    4    |\n",
            " |      +------------+-----------+------------+-----------------+---+---------+\n",
            " |      |  'rbf'     |     0.1   |     --     |       0.80      |...|    3    |\n",
            " |      +------------+-----------+------------+-----------------+---+---------+\n",
            " |      |  'rbf'     |     0.2   |     --     |       0.93      |...|    1    |\n",
            " |      +------------+-----------+------------+-----------------+---+---------+\n",
            " |  \n",
            " |      will be represented by a ``cv_results_`` dict of::\n",
            " |  \n",
            " |          {\n",
            " |          'param_kernel': masked_array(data = ['poly', 'poly', 'rbf', 'rbf'],\n",
            " |                                       mask = [False False False False]...)\n",
            " |          'param_gamma': masked_array(data = [-- -- 0.1 0.2],\n",
            " |                                      mask = [ True  True False False]...),\n",
            " |          'param_degree': masked_array(data = [2.0 3.0 -- --],\n",
            " |                                       mask = [False False  True  True]...),\n",
            " |          'split0_test_score'  : [0.80, 0.70, 0.80, 0.93],\n",
            " |          'split1_test_score'  : [0.82, 0.50, 0.70, 0.78],\n",
            " |          'mean_test_score'    : [0.81, 0.60, 0.75, 0.85],\n",
            " |          'std_test_score'     : [0.01, 0.10, 0.05, 0.08],\n",
            " |          'rank_test_score'    : [2, 4, 3, 1],\n",
            " |          'split0_train_score' : [0.80, 0.92, 0.70, 0.93],\n",
            " |          'split1_train_score' : [0.82, 0.55, 0.70, 0.87],\n",
            " |          'mean_train_score'   : [0.81, 0.74, 0.70, 0.90],\n",
            " |          'std_train_score'    : [0.01, 0.19, 0.00, 0.03],\n",
            " |          'mean_fit_time'      : [0.73, 0.63, 0.43, 0.49],\n",
            " |          'std_fit_time'       : [0.01, 0.02, 0.01, 0.01],\n",
            " |          'mean_score_time'    : [0.01, 0.06, 0.04, 0.04],\n",
            " |          'std_score_time'     : [0.00, 0.00, 0.00, 0.01],\n",
            " |          'params'             : [{'kernel': 'poly', 'degree': 2}, ...],\n",
            " |          }\n",
            " |  \n",
            " |      NOTE\n",
            " |  \n",
            " |      The key ``'params'`` is used to store a list of parameter\n",
            " |      settings dicts for all the parameter candidates.\n",
            " |  \n",
            " |      The ``mean_fit_time``, ``std_fit_time``, ``mean_score_time`` and\n",
            " |      ``std_score_time`` are all in seconds.\n",
            " |  \n",
            " |      For multi-metric evaluation, the scores for all the scorers are\n",
            " |      available in the ``cv_results_`` dict at the keys ending with that\n",
            " |      scorer's name (``'_<scorer_name>'``) instead of ``'_score'`` shown\n",
            " |      above. ('split0_test_precision', 'mean_train_precision' etc.)\n",
            " |  \n",
            " |  best_estimator_ : estimator\n",
            " |      Estimator that was chosen by the search, i.e. estimator\n",
            " |      which gave highest score (or smallest loss if specified)\n",
            " |      on the left out data. Not available if ``refit=False``.\n",
            " |  \n",
            " |      See ``refit`` parameter for more information on allowed values.\n",
            " |  \n",
            " |  best_score_ : float\n",
            " |      Mean cross-validated score of the best_estimator\n",
            " |  \n",
            " |      For multi-metric evaluation, this is present only if ``refit`` is\n",
            " |      specified.\n",
            " |  \n",
            " |      This attribute is not available if ``refit`` is a function.\n",
            " |  \n",
            " |  best_params_ : dict\n",
            " |      Parameter setting that gave the best results on the hold out data.\n",
            " |  \n",
            " |      For multi-metric evaluation, this is present only if ``refit`` is\n",
            " |      specified.\n",
            " |  \n",
            " |  best_index_ : int\n",
            " |      The index (of the ``cv_results_`` arrays) which corresponds to the best\n",
            " |      candidate parameter setting.\n",
            " |  \n",
            " |      The dict at ``search.cv_results_['params'][search.best_index_]`` gives\n",
            " |      the parameter setting for the best model, that gives the highest\n",
            " |      mean score (``search.best_score_``).\n",
            " |  \n",
            " |      For multi-metric evaluation, this is present only if ``refit`` is\n",
            " |      specified.\n",
            " |  \n",
            " |  scorer_ : function or a dict\n",
            " |      Scorer function used on the held out data to choose the best\n",
            " |      parameters for the model.\n",
            " |  \n",
            " |      For multi-metric evaluation, this attribute holds the validated\n",
            " |      ``scoring`` dict which maps the scorer key to the scorer callable.\n",
            " |  \n",
            " |  n_splits_ : int\n",
            " |      The number of cross-validation splits (folds/iterations).\n",
            " |  \n",
            " |  refit_time_ : float\n",
            " |      Seconds used for refitting the best model on the whole dataset.\n",
            " |  \n",
            " |      This is present only if ``refit`` is not False.\n",
            " |  \n",
            " |      .. versionadded:: 0.20\n",
            " |  \n",
            " |  multimetric_ : bool\n",
            " |      Whether or not the scorers compute several metrics.\n",
            " |  \n",
            " |  classes_ : ndarray of shape (n_classes,)\n",
            " |      The classes labels. This is present only if ``refit`` is specified and\n",
            " |      the underlying estimator is a classifier.\n",
            " |  \n",
            " |  n_features_in_ : int\n",
            " |      Number of features seen during :term:`fit`. Only defined if\n",
            " |      `best_estimator_` is defined (see the documentation for the `refit`\n",
            " |      parameter for more details) and that `best_estimator_` exposes\n",
            " |      `n_features_in_` when fit.\n",
            " |  \n",
            " |      .. versionadded:: 0.24\n",
            " |  \n",
            " |  feature_names_in_ : ndarray of shape (`n_features_in_`,)\n",
            " |      Names of features seen during :term:`fit`. Only defined if\n",
            " |      `best_estimator_` is defined (see the documentation for the `refit`\n",
            " |      parameter for more details) and that `best_estimator_` exposes\n",
            " |      `feature_names_in_` when fit.\n",
            " |  \n",
            " |      .. versionadded:: 1.0\n",
            " |  \n",
            " |  See Also\n",
            " |  --------\n",
            " |  ParameterGrid : Generates all the combinations of a hyperparameter grid.\n",
            " |  train_test_split : Utility function to split the data into a development\n",
            " |      set usable for fitting a GridSearchCV instance and an evaluation set\n",
            " |      for its final evaluation.\n",
            " |  sklearn.metrics.make_scorer : Make a scorer from a performance metric or\n",
            " |      loss function.\n",
            " |  \n",
            " |  Notes\n",
            " |  -----\n",
            " |  The parameters selected are those that maximize the score of the left out\n",
            " |  data, unless an explicit score is passed in which case it is used instead.\n",
            " |  \n",
            " |  If `n_jobs` was set to a value higher than one, the data is copied for each\n",
            " |  point in the grid (and not `n_jobs` times). This is done for efficiency\n",
            " |  reasons if individual jobs take very little time, but may raise errors if\n",
            " |  the dataset is large and not enough memory is available.  A workaround in\n",
            " |  this case is to set `pre_dispatch`. Then, the memory is copied only\n",
            " |  `pre_dispatch` many times. A reasonable value for `pre_dispatch` is `2 *\n",
            " |  n_jobs`.\n",
            " |  \n",
            " |  Examples\n",
            " |  --------\n",
            " |  >>> from sklearn import svm, datasets\n",
            " |  >>> from sklearn.model_selection import GridSearchCV\n",
            " |  >>> iris = datasets.load_iris()\n",
            " |  >>> parameters = {'kernel':('linear', 'rbf'), 'C':[1, 10]}\n",
            " |  >>> svc = svm.SVC()\n",
            " |  >>> clf = GridSearchCV(svc, parameters)\n",
            " |  >>> clf.fit(iris.data, iris.target)\n",
            " |  GridSearchCV(estimator=SVC(),\n",
            " |               param_grid={'C': [1, 10], 'kernel': ('linear', 'rbf')})\n",
            " |  >>> sorted(clf.cv_results_.keys())\n",
            " |  ['mean_fit_time', 'mean_score_time', 'mean_test_score',...\n",
            " |   'param_C', 'param_kernel', 'params',...\n",
            " |   'rank_test_score', 'split0_test_score',...\n",
            " |   'split2_test_score', ...\n",
            " |   'std_fit_time', 'std_score_time', 'std_test_score']\n",
            " |  \n",
            " |  Method resolution order:\n",
            " |      GridSearchCV\n",
            " |      BaseSearchCV\n",
            " |      sklearn.base.MetaEstimatorMixin\n",
            " |      sklearn.base.BaseEstimator\n",
            " |      builtins.object\n",
            " |  \n",
            " |  Methods defined here:\n",
            " |  \n",
            " |  __init__(self, estimator, param_grid, *, scoring=None, n_jobs=None, refit=True, cv=None, verbose=0, pre_dispatch='2*n_jobs', error_score=nan, return_train_score=False)\n",
            " |      Initialize self.  See help(type(self)) for accurate signature.\n",
            " |  \n",
            " |  ----------------------------------------------------------------------\n",
            " |  Data and other attributes defined here:\n",
            " |  \n",
            " |  __abstractmethods__ = frozenset()\n",
            " |  \n",
            " |  __annotations__ = {}\n",
            " |  \n",
            " |  ----------------------------------------------------------------------\n",
            " |  Methods inherited from BaseSearchCV:\n",
            " |  \n",
            " |  decision_function(self, X)\n",
            " |      Call decision_function on the estimator with the best found parameters.\n",
            " |      \n",
            " |      Only available if ``refit=True`` and the underlying estimator supports\n",
            " |      ``decision_function``.\n",
            " |      \n",
            " |      Parameters\n",
            " |      ----------\n",
            " |      X : indexable, length n_samples\n",
            " |          Must fulfill the input assumptions of the\n",
            " |          underlying estimator.\n",
            " |      \n",
            " |      Returns\n",
            " |      -------\n",
            " |      y_score : ndarray of shape (n_samples,) or (n_samples, n_classes)                 or (n_samples, n_classes * (n_classes-1) / 2)\n",
            " |          Result of the decision function for `X` based on the estimator with\n",
            " |          the best found parameters.\n",
            " |  \n",
            " |  fit(self, X, y=None, *, groups=None, **fit_params)\n",
            " |      Run fit with all sets of parameters.\n",
            " |      \n",
            " |      Parameters\n",
            " |      ----------\n",
            " |      \n",
            " |      X : array-like of shape (n_samples, n_features)\n",
            " |          Training vector, where `n_samples` is the number of samples and\n",
            " |          `n_features` is the number of features.\n",
            " |      \n",
            " |      y : array-like of shape (n_samples, n_output)             or (n_samples,), default=None\n",
            " |          Target relative to X for classification or regression;\n",
            " |          None for unsupervised learning.\n",
            " |      \n",
            " |      groups : array-like of shape (n_samples,), default=None\n",
            " |          Group labels for the samples used while splitting the dataset into\n",
            " |          train/test set. Only used in conjunction with a \"Group\" :term:`cv`\n",
            " |          instance (e.g., :class:`~sklearn.model_selection.GroupKFold`).\n",
            " |      \n",
            " |      **fit_params : dict of str -> object\n",
            " |          Parameters passed to the `fit` method of the estimator.\n",
            " |      \n",
            " |          If a fit parameter is an array-like whose length is equal to\n",
            " |          `num_samples` then it will be split across CV groups along with `X`\n",
            " |          and `y`. For example, the :term:`sample_weight` parameter is split\n",
            " |          because `len(sample_weights) = len(X)`.\n",
            " |      \n",
            " |      Returns\n",
            " |      -------\n",
            " |      self : object\n",
            " |          Instance of fitted estimator.\n",
            " |  \n",
            " |  inverse_transform(self, Xt)\n",
            " |      Call inverse_transform on the estimator with the best found params.\n",
            " |      \n",
            " |      Only available if the underlying estimator implements\n",
            " |      ``inverse_transform`` and ``refit=True``.\n",
            " |      \n",
            " |      Parameters\n",
            " |      ----------\n",
            " |      Xt : indexable, length n_samples\n",
            " |          Must fulfill the input assumptions of the\n",
            " |          underlying estimator.\n",
            " |      \n",
            " |      Returns\n",
            " |      -------\n",
            " |      X : {ndarray, sparse matrix} of shape (n_samples, n_features)\n",
            " |          Result of the `inverse_transform` function for `Xt` based on the\n",
            " |          estimator with the best found parameters.\n",
            " |  \n",
            " |  predict(self, X)\n",
            " |      Call predict on the estimator with the best found parameters.\n",
            " |      \n",
            " |      Only available if ``refit=True`` and the underlying estimator supports\n",
            " |      ``predict``.\n",
            " |      \n",
            " |      Parameters\n",
            " |      ----------\n",
            " |      X : indexable, length n_samples\n",
            " |          Must fulfill the input assumptions of the\n",
            " |          underlying estimator.\n",
            " |      \n",
            " |      Returns\n",
            " |      -------\n",
            " |      y_pred : ndarray of shape (n_samples,)\n",
            " |          The predicted labels or values for `X` based on the estimator with\n",
            " |          the best found parameters.\n",
            " |  \n",
            " |  predict_log_proba(self, X)\n",
            " |      Call predict_log_proba on the estimator with the best found parameters.\n",
            " |      \n",
            " |      Only available if ``refit=True`` and the underlying estimator supports\n",
            " |      ``predict_log_proba``.\n",
            " |      \n",
            " |      Parameters\n",
            " |      ----------\n",
            " |      X : indexable, length n_samples\n",
            " |          Must fulfill the input assumptions of the\n",
            " |          underlying estimator.\n",
            " |      \n",
            " |      Returns\n",
            " |      -------\n",
            " |      y_pred : ndarray of shape (n_samples,) or (n_samples, n_classes)\n",
            " |          Predicted class log-probabilities for `X` based on the estimator\n",
            " |          with the best found parameters. The order of the classes\n",
            " |          corresponds to that in the fitted attribute :term:`classes_`.\n",
            " |  \n",
            " |  predict_proba(self, X)\n",
            " |      Call predict_proba on the estimator with the best found parameters.\n",
            " |      \n",
            " |      Only available if ``refit=True`` and the underlying estimator supports\n",
            " |      ``predict_proba``.\n",
            " |      \n",
            " |      Parameters\n",
            " |      ----------\n",
            " |      X : indexable, length n_samples\n",
            " |          Must fulfill the input assumptions of the\n",
            " |          underlying estimator.\n",
            " |      \n",
            " |      Returns\n",
            " |      -------\n",
            " |      y_pred : ndarray of shape (n_samples,) or (n_samples, n_classes)\n",
            " |          Predicted class probabilities for `X` based on the estimator with\n",
            " |          the best found parameters. The order of the classes corresponds\n",
            " |          to that in the fitted attribute :term:`classes_`.\n",
            " |  \n",
            " |  score(self, X, y=None)\n",
            " |      Return the score on the given data, if the estimator has been refit.\n",
            " |      \n",
            " |      This uses the score defined by ``scoring`` where provided, and the\n",
            " |      ``best_estimator_.score`` method otherwise.\n",
            " |      \n",
            " |      Parameters\n",
            " |      ----------\n",
            " |      X : array-like of shape (n_samples, n_features)\n",
            " |          Input data, where `n_samples` is the number of samples and\n",
            " |          `n_features` is the number of features.\n",
            " |      \n",
            " |      y : array-like of shape (n_samples, n_output)             or (n_samples,), default=None\n",
            " |          Target relative to X for classification or regression;\n",
            " |          None for unsupervised learning.\n",
            " |      \n",
            " |      Returns\n",
            " |      -------\n",
            " |      score : float\n",
            " |          The score defined by ``scoring`` if provided, and the\n",
            " |          ``best_estimator_.score`` method otherwise.\n",
            " |  \n",
            " |  score_samples(self, X)\n",
            " |      Call score_samples on the estimator with the best found parameters.\n",
            " |      \n",
            " |      Only available if ``refit=True`` and the underlying estimator supports\n",
            " |      ``score_samples``.\n",
            " |      \n",
            " |      .. versionadded:: 0.24\n",
            " |      \n",
            " |      Parameters\n",
            " |      ----------\n",
            " |      X : iterable\n",
            " |          Data to predict on. Must fulfill input requirements\n",
            " |          of the underlying estimator.\n",
            " |      \n",
            " |      Returns\n",
            " |      -------\n",
            " |      y_score : ndarray of shape (n_samples,)\n",
            " |          The ``best_estimator_.score_samples`` method.\n",
            " |  \n",
            " |  transform(self, X)\n",
            " |      Call transform on the estimator with the best found parameters.\n",
            " |      \n",
            " |      Only available if the underlying estimator supports ``transform`` and\n",
            " |      ``refit=True``.\n",
            " |      \n",
            " |      Parameters\n",
            " |      ----------\n",
            " |      X : indexable, length n_samples\n",
            " |          Must fulfill the input assumptions of the\n",
            " |          underlying estimator.\n",
            " |      \n",
            " |      Returns\n",
            " |      -------\n",
            " |      Xt : {ndarray, sparse matrix} of shape (n_samples, n_features)\n",
            " |          `X` transformed in the new space based on the estimator with\n",
            " |          the best found parameters.\n",
            " |  \n",
            " |  ----------------------------------------------------------------------\n",
            " |  Readonly properties inherited from BaseSearchCV:\n",
            " |  \n",
            " |  classes_\n",
            " |      Class labels.\n",
            " |      \n",
            " |      Only available when `refit=True` and the estimator is a classifier.\n",
            " |  \n",
            " |  n_features_in_\n",
            " |      Number of features seen during :term:`fit`.\n",
            " |      \n",
            " |      Only available when `refit=True`.\n",
            " |  \n",
            " |  ----------------------------------------------------------------------\n",
            " |  Data descriptors inherited from sklearn.base.MetaEstimatorMixin:\n",
            " |  \n",
            " |  __dict__\n",
            " |      dictionary for instance variables (if defined)\n",
            " |  \n",
            " |  __weakref__\n",
            " |      list of weak references to the object (if defined)\n",
            " |  \n",
            " |  ----------------------------------------------------------------------\n",
            " |  Methods inherited from sklearn.base.BaseEstimator:\n",
            " |  \n",
            " |  __getstate__(self)\n",
            " |  \n",
            " |  __repr__(self, N_CHAR_MAX=700)\n",
            " |      Return repr(self).\n",
            " |  \n",
            " |  __setstate__(self, state)\n",
            " |  \n",
            " |  get_params(self, deep=True)\n",
            " |      Get parameters for this estimator.\n",
            " |      \n",
            " |      Parameters\n",
            " |      ----------\n",
            " |      deep : bool, default=True\n",
            " |          If True, will return the parameters for this estimator and\n",
            " |          contained subobjects that are estimators.\n",
            " |      \n",
            " |      Returns\n",
            " |      -------\n",
            " |      params : dict\n",
            " |          Parameter names mapped to their values.\n",
            " |  \n",
            " |  set_params(self, **params)\n",
            " |      Set the parameters of this estimator.\n",
            " |      \n",
            " |      The method works on simple estimators as well as on nested objects\n",
            " |      (such as :class:`~sklearn.pipeline.Pipeline`). The latter have\n",
            " |      parameters of the form ``<component>__<parameter>`` so that it's\n",
            " |      possible to update each component of a nested object.\n",
            " |      \n",
            " |      Parameters\n",
            " |      ----------\n",
            " |      **params : dict\n",
            " |          Estimator parameters.\n",
            " |      \n",
            " |      Returns\n",
            " |      -------\n",
            " |      self : estimator instance\n",
            " |          Estimator instance.\n",
            "\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# GridSearch CV를 활용한 하이퍼파라미터 최적화\n",
        "# - GridSearch : 격자탐색\n",
        "# - CV = CrossValidation, 교차검증\n",
        "# (주의) 별도로 train/val 분리가 필요하지 않음\n",
        "\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "rf_params = { 'n_estimators' : [30,70,100],\n",
        "             'max_depth' : [6, 8, 10],\n",
        "              'min_samples_leaf' : [1, 2, 3],\n",
        "}\n",
        "\n",
        "# n_estimators : tree의 개수\n",
        "# max_depth : tree의 최대 깊이\n",
        "# min_samples_leaf : leaf node(더이상 분할되지 않는 마지막 노드)가 되기 위해 필요한 최소 샘플 수\n",
        "# (이 값보다 작은 수의 샘플이 해당 노드에 있을 경우, 더 이상 분할하지 않음)\n",
        "\n",
        "# RandomForestClassifier 객체 생성 후 GridSearchCV 수행\n",
        "\n",
        "rf = RandomForestClassifier(random_state = 2023)\n",
        "grid_rf = GridSearchCV(rf, param_grid = rf_params, cv = 10)\n",
        "grid_rf.fit(x_train_ad, y_train_ad['target'])\n",
        "\n",
        "print('최적 하이퍼파라미터: ', grid_rf.best_params_)\n",
        "print('Best 예측정확도: ', grid_rf.best_score_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kNEkA3F4FyBq",
        "outputId": "f9f1addf-3c87-41fd-8625-9e16f7771e89"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "최적 하이퍼파라미터:  {'max_depth': 10, 'min_samples_leaf': 3, 'n_estimators': 70}\n",
            "Best 예측정확도:  0.8427034428794992\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# (참고) help 함수를 통한 함수 사용법 확인\n",
        "# from sklearn.model_selection import GridSearchCV\n",
        "# help(GridSearchCV)\n",
        "# from sklearn.ensemble import RandomForestClassifier\n",
        "# help(RandomForestClassifier)"
      ],
      "metadata": {
        "id": "BzKuc4jLJ6LJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 위의 최적 하이퍼파라미터로 랜덤포레스트 모델을 생성\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "model_h = RandomForestClassifier(n_estimators = 70,\n",
        "                                 max_depth = 10,\n",
        "                                 min_samples_leaf = 3,\n",
        "                                 random_state = 2023)\n",
        "model_h.fit(x_train_ad, y_train_ad['target'] )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 92
        },
        "id": "Yd82WObBJ53J",
        "outputId": "d36bd17d-f819-4622-bf08-31fcbdc3fdb3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomForestClassifier(max_depth=10, min_samples_leaf=3, n_estimators=70,\n",
              "                       random_state=2023)"
            ],
            "text/html": [
              "<style>#sk-container-id-5 {color: black;background-color: white;}#sk-container-id-5 pre{padding: 0;}#sk-container-id-5 div.sk-toggleable {background-color: white;}#sk-container-id-5 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-5 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-5 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-5 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-5 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-5 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-5 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-5 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-5 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-5 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-5 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-5 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-5 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-5 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-5 div.sk-item {position: relative;z-index: 1;}#sk-container-id-5 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-5 div.sk-item::before, #sk-container-id-5 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-5 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-5 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-5 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-5 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-5 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-5 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-5 div.sk-label-container {text-align: center;}#sk-container-id-5 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-5 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-5\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(max_depth=10, min_samples_leaf=3, n_estimators=70,\n",
              "                       random_state=2023)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" checked><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(max_depth=10, min_samples_leaf=3, n_estimators=70,\n",
              "                       random_state=2023)</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 129
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 모델 성능 평가 (정확도, F1 score, AUC)\n",
        "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score\n",
        "\n",
        "# test 데이터셋으로 성능평가\n",
        "y_pred_h = model_h.predict(x_test)\n",
        "acc_h = accuracy_score(y_test, y_pred_h) # (실제값, 예측값)\n",
        "f1_h = f1_score(y_test, y_pred_h) # (실제값, 예측값)\n",
        "auc_h = roc_auc_score(y_test, y_pred_h) # (실제값, 예측값)\n",
        "print('HP 최적화 Acc:', acc_h )\n",
        "print('HP 최적화 f1:', f1_h )\n",
        "print('HP 최적화:AUC', auc_h )\n",
        "# HP : Hyperparameter\n",
        "\n",
        "print('기본모델 Acc:', acc_f)\n",
        "print('기본모델 f1:', f1_f )\n",
        "print('기본모델 AUC:', auc_f )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ut7VsfwfKAuX",
        "outputId": "a690e943-c822-40d9-d148-f0bbf849eb7f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "HP 최적화 Acc: 0.7988826815642458\n",
            "HP 최적화 f1: 0.7272727272727272\n",
            "HP 최적화:AUC 0.7796442687747035\n",
            "기본모델 Acc: 0.7821229050279329\n",
            "기본모델 f1: 0.7153284671532847\n",
            "기본모델 AUC: 0.7687088274044797\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# (실기시험 안내사항)\n",
        "# 아래 코드 예측변수와 수험번호를 개인별로 변경하여 활용\n",
        "# pd.DataFrame({ 'result': y_result }).to_csv('수험번호.csv', index=False)\n",
        "# 모델을 사용하여 테스트 데이터 예측\n",
        "y_result = model.predict(x_test)\n",
        "# 1. 특정 클래스로 분류할 경우 (predict)\n",
        "y_result = model.predict(x_test)\n",
        "print(y_result[:5])\n",
        "# 2. 특정 클래스로 분류될 확률을 구할 경우 (predict_proba)\n",
        "y_result_prob = model.predict_proba(x_test)\n",
        "print(y_result_prob[:5])\n",
        "# 이해해보기\n",
        "result_prob = pd.DataFrame({\n",
        "'result': y_result,\n",
        "'prob_0': y_result_prob[:,0]\n",
        "})\n",
        "# Class가 0일 확률 : y_result_prob[:,0]\n",
        "# Class가 1일 확률 : y_result_prob[:,1]\n",
        "print(result_prob[:5])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vGQ0zrfFKcr8",
        "outputId": "72f43060-ed89-4789-fab2-61f0974237f8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1 1 0 0 0]\n",
            "[[0.32 0.68]\n",
            " [0.24 0.76]\n",
            " [1.   0.  ]\n",
            " [0.93 0.07]\n",
            " [0.93 0.07]]\n",
            "   result  prob_0\n",
            "0       1    0.32\n",
            "1       1    0.24\n",
            "2       0    1.00\n",
            "3       0    0.93\n",
            "4       0    0.93\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 제2유형_연습하기_당뇨진척정도(회귀)\n",
        "✅ 데이터 분석 순서\n",
        "1. 라이브러리 및 데이터 확인\n",
        "2. 데이터 탐색(EDA)\n",
        "3. 데이터 전처리 및 분리\n",
        "4. 모델링 및 성능평가\n",
        "5. 예측값 제출"
      ],
      "metadata": {
        "id": "k4fQOOAdK5YH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1) 라이브러리 및 데이터 확인"
      ],
      "metadata": {
        "id": "CGBlwisoMvNP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "PyUmYMqKMxt8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "# 실기 시험 데이터셋으로 셋팅하기 (수정금지)\n",
        "from sklearn.datasets import load_diabetes\n",
        "# diabetes 데이터셋 로드\n",
        "diabetes = load_diabetes()\n",
        "x = pd.DataFrame(diabetes.data, columns=diabetes.feature_names)\n",
        "y = pd.DataFrame(diabetes.target)\n",
        "# 실기 시험 데이터셋으로 셋팅하기 (수정금지)\n",
        "from sklearn.model_selection import train_test_split\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=2023)\n",
        "x_test = pd.DataFrame(x_test.reset_index())\n",
        "x_train = pd.DataFrame(x_train.reset_index())\n",
        "y_train = pd.DataFrame(y_train.reset_index())\n",
        "x_test.rename(columns={'index':'cust_id'}, inplace=True)\n",
        "x_train.rename(columns={'index':'cust_id'}, inplace=True)\n",
        "y_train.columns = ['cust_id', 'target']"
      ],
      "metadata": {
        "id": "gfXrZ_t9M3ep"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "당뇨병 환자의 질병 진행정도를 예측해보자\n",
        "- 데이터의 결측치, 이상치, 변수들에 대해 전처리하고\n",
        "- 회귀모델을 사용하여 Rsq, MSE 값을 산출하시오.\n",
        "- 제출은 cust_id, target 변수를 가진 dataframe 형태로 제출하시오."
      ],
      "metadata": {
        "id": "4QI2KJLWM82W"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2) 데이텀 탐색(EDA)"
      ],
      "metadata": {
        "id": "ELtAr0aWahHD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 데이터의 행/열 확인\n",
        "\n",
        "print(x_train.shape)\n",
        "print(x_test.shape)\n",
        "print(y_train.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AT9v_5q5agT-",
        "outputId": "44f5ff98-9e1b-4b45-ba07-b7537ab33d3d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(353, 11)\n",
            "(89, 11)\n",
            "(353, 2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 초기 데이터 확인\n",
        "print(x_train.head(3))\n",
        "print(x_test.head(3))\n",
        "print(y_train.head(3))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cGAYxZzBa5NO",
        "outputId": "ad4b76e0-63ce-4b27-bc7a-c3a6382de30e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   cust_id       age       sex       bmi        bp        s1        s2  \\\n",
            "0        4  0.005383 -0.044642 -0.036385  0.021872  0.003935  0.015596   \n",
            "1      318  0.088931 -0.044642  0.006728  0.025315  0.030078  0.008707   \n",
            "2      301 -0.001882  0.050680 -0.024529  0.052858  0.027326  0.030001   \n",
            "\n",
            "         s3        s4        s5        s6  \n",
            "0  0.008142 -0.002592 -0.031988 -0.046641  \n",
            "1  0.063367 -0.039493  0.009434  0.032059  \n",
            "2  0.030232 -0.002592 -0.021395  0.036201  \n",
            "   cust_id       age       sex       bmi        bp        s1        s2  \\\n",
            "0      280  0.009016  0.050680  0.018584  0.039087  0.017694  0.010586   \n",
            "1      412  0.074401 -0.044642  0.085408  0.063187  0.014942  0.013091   \n",
            "2       68  0.038076  0.050680 -0.029918 -0.040099 -0.033216 -0.024174   \n",
            "\n",
            "         s3        s4        s5        s6  \n",
            "0  0.019187 -0.002592  0.016307 -0.017646  \n",
            "1  0.015505 -0.002592  0.006207  0.085907  \n",
            "2 -0.010266 -0.002592 -0.012909  0.003064  \n",
            "   cust_id  target\n",
            "0        4   135.0\n",
            "1      318   109.0\n",
            "2      301    65.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 변수명과 데이터 타입이 매칭이 되는지, 결측치가 있는지 확인\n",
        "print(x_train.info())\n",
        "print(x_test.info())\n",
        "print(y_train.info())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IJw1i9TWbDYl",
        "outputId": "8fd1c3f6-6304-4ff8-a2fd-ecf1ca863c32"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 353 entries, 0 to 352\n",
            "Data columns (total 11 columns):\n",
            " #   Column   Non-Null Count  Dtype  \n",
            "---  ------   --------------  -----  \n",
            " 0   cust_id  353 non-null    int64  \n",
            " 1   age      353 non-null    float64\n",
            " 2   sex      353 non-null    float64\n",
            " 3   bmi      353 non-null    float64\n",
            " 4   bp       353 non-null    float64\n",
            " 5   s1       353 non-null    float64\n",
            " 6   s2       353 non-null    float64\n",
            " 7   s3       353 non-null    float64\n",
            " 8   s4       353 non-null    float64\n",
            " 9   s5       353 non-null    float64\n",
            " 10  s6       353 non-null    float64\n",
            "dtypes: float64(10), int64(1)\n",
            "memory usage: 30.5 KB\n",
            "None\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 89 entries, 0 to 88\n",
            "Data columns (total 11 columns):\n",
            " #   Column   Non-Null Count  Dtype  \n",
            "---  ------   --------------  -----  \n",
            " 0   cust_id  89 non-null     int64  \n",
            " 1   age      89 non-null     float64\n",
            " 2   sex      89 non-null     float64\n",
            " 3   bmi      89 non-null     float64\n",
            " 4   bp       89 non-null     float64\n",
            " 5   s1       89 non-null     float64\n",
            " 6   s2       89 non-null     float64\n",
            " 7   s3       89 non-null     float64\n",
            " 8   s4       89 non-null     float64\n",
            " 9   s5       89 non-null     float64\n",
            " 10  s6       89 non-null     float64\n",
            "dtypes: float64(10), int64(1)\n",
            "memory usage: 7.8 KB\n",
            "None\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 353 entries, 0 to 352\n",
            "Data columns (total 2 columns):\n",
            " #   Column   Non-Null Count  Dtype  \n",
            "---  ------   --------------  -----  \n",
            " 0   cust_id  353 non-null    int64  \n",
            " 1   target   353 non-null    float64\n",
            "dtypes: float64(1), int64(1)\n",
            "memory usage: 5.6 KB\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 기초통계량 확인\n",
        "\n",
        "print(x_train.describe())\n",
        "print(x_test.describe())\n",
        "print(y_train.describe())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y5KSu9IEbS08",
        "outputId": "e3d2641f-879e-4126-925a-5a5141f1e89f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "          cust_id         age         sex         bmi          bp          s1  \\\n",
            "count  353.000000  353.000000  353.000000  353.000000  353.000000  353.000000   \n",
            "mean   212.634561    0.000804    0.000724    0.000640   -0.000326    0.001179   \n",
            "std    126.668903    0.047617    0.047673    0.048141    0.046585    0.047891   \n",
            "min      0.000000   -0.107226   -0.044642   -0.084886   -0.112399   -0.126781   \n",
            "25%    105.000000   -0.038207   -0.044642   -0.035307   -0.033213   -0.033216   \n",
            "50%    210.000000    0.005383   -0.044642   -0.006206   -0.005670   -0.002945   \n",
            "75%    322.000000    0.038076    0.050680    0.030440    0.032201    0.027326   \n",
            "max    441.000000    0.110727    0.050680    0.170555    0.125158    0.153914   \n",
            "\n",
            "               s2          s3          s4          s5          s6  \n",
            "count  353.000000  353.000000  353.000000  353.000000  353.000000  \n",
            "mean     0.001110   -0.000452    0.000901    0.001446    0.000589  \n",
            "std      0.048248    0.048600    0.048045    0.047160    0.048122  \n",
            "min     -0.115613   -0.102307   -0.076395   -0.126097   -0.137767  \n",
            "25%     -0.029184   -0.039719   -0.039493   -0.033246   -0.034215  \n",
            "50%     -0.001314   -0.006584   -0.002592    0.000272    0.003064  \n",
            "75%      0.031567    0.030232    0.034309    0.033654    0.032059  \n",
            "max      0.198788    0.181179    0.185234    0.133597    0.135612  \n",
            "          cust_id        age        sex        bmi         bp         s1  \\\n",
            "count   89.000000  89.000000  89.000000  89.000000  89.000000  89.000000   \n",
            "mean   251.696629  -0.003188  -0.002871  -0.002537   0.001292  -0.004676   \n",
            "std    127.901365   0.047761   0.047563   0.045665   0.051777   0.046493   \n",
            "min      9.000000  -0.099961  -0.044642  -0.090275  -0.108956  -0.091006   \n",
            "25%    148.000000  -0.034575  -0.044642  -0.030996  -0.036656  -0.037344   \n",
            "50%    280.000000  -0.001882  -0.044642  -0.009439  -0.005670  -0.009825   \n",
            "75%    366.000000   0.030811   0.050680   0.034751   0.042529   0.031454   \n",
            "max    436.000000   0.096197   0.050680   0.137143   0.132044   0.119515   \n",
            "\n",
            "              s2         s3         s4         s5         s6  \n",
            "count  89.000000  89.000000  89.000000  89.000000  89.000000  \n",
            "mean   -0.004401   0.001792  -0.003575  -0.005737  -0.002334  \n",
            "std     0.045030   0.043723   0.045980   0.049252   0.045757  \n",
            "min    -0.089935  -0.080217  -0.076395  -0.104366  -0.129483  \n",
            "25%    -0.030437  -0.028674  -0.039493  -0.038460  -0.030072  \n",
            "50%    -0.014153  -0.002903  -0.002592  -0.014960  -0.005220  \n",
            "75%     0.020607   0.022869   0.003312   0.024055   0.019633  \n",
            "max     0.130208   0.122273   0.141322   0.133597   0.135612  \n",
            "          cust_id      target\n",
            "count  353.000000  353.000000\n",
            "mean   212.634561  152.943343\n",
            "std    126.668903   75.324692\n",
            "min      0.000000   37.000000\n",
            "25%    105.000000   90.000000\n",
            "50%    210.000000  141.000000\n",
            "75%    322.000000  208.000000\n",
            "max    441.000000  346.000000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# y데이터도 구체적으로 확인\n",
        "print(y_train.head())\n",
        "print(y_train.describe())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zB8HUZQofLmG",
        "outputId": "2fb4c113-9ed7-4bfc-d45f-793799818f27"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   cust_id  target\n",
            "0        4   135.0\n",
            "1      318   109.0\n",
            "2      301    65.0\n",
            "3      189    79.0\n",
            "4      288    80.0\n",
            "          cust_id      target\n",
            "count  353.000000  353.000000\n",
            "mean   212.634561  152.943343\n",
            "std    126.668903   75.324692\n",
            "min      0.000000   37.000000\n",
            "25%    105.000000   90.000000\n",
            "50%    210.000000  141.000000\n",
            "75%    322.000000  208.000000\n",
            "max    441.000000  346.000000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3) 데이터 전처리 및 분리"
      ],
      "metadata": {
        "id": "Dc9A1Ra0fsx_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 결측치 확인\n",
        "print(x_train.isnull().sum())\n",
        "print(x_test.isnull().sum())\n",
        "print(y_train.isnull().sum())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MOihTjIAfvva",
        "outputId": "484c5f44-5a84-4e23-a319-19930d3a3b3d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cust_id    0\n",
            "age        0\n",
            "sex        0\n",
            "bmi        0\n",
            "bp         0\n",
            "s1         0\n",
            "s2         0\n",
            "s3         0\n",
            "s4         0\n",
            "s5         0\n",
            "s6         0\n",
            "dtype: int64\n",
            "cust_id    0\n",
            "age        0\n",
            "sex        0\n",
            "bmi        0\n",
            "bp         0\n",
            "s1         0\n",
            "s2         0\n",
            "s3         0\n",
            "s4         0\n",
            "s5         0\n",
            "s6         0\n",
            "dtype: int64\n",
            "cust_id    0\n",
            "target     0\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 변수처리\n",
        "# 불필요한 변수(columns) 제거\n",
        "# cust_id 는 불필요한 변수이므로 제거합니다.\n",
        "# 단, test 셋의 cust_id가 나중에 제출이 필요하기 때문에 별도로 저장\n",
        "\n",
        "cust_id = x_test['cust_id'].copy() # 변수에 저장 후 제거\n",
        "\n",
        "x_train = x_train.drop(columns=['cust_id'])\n",
        "x_test = x_test.drop(columns=['cust_id'])"
      ],
      "metadata": {
        "id": "6XkRIVfCitgq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 데이터 분리\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train['target'], test_size=0.2, random_state=23)\n",
        "\n",
        "print(x_train.shape)\n",
        "print(x_val.shape)\n",
        "print(y_train.shape)\n",
        "print(y_val.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f1DqbZ1FjKXX",
        "outputId": "07d26b47-c59d-4a0a-90a7-de8f5e1e5ef4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(282, 10)\n",
            "(71, 10)\n",
            "(282,)\n",
            "(71,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4) 모델링 및 성능평가"
      ],
      "metadata": {
        "id": "EeGQfLYtO7rh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 랜덤포레스트 모델 사용\n",
        "\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "model = RandomForestRegressor(random_state=2023)\n",
        "model.fit(x_train, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 75
        },
        "id": "NqgO0jrwO68q",
        "outputId": "9c8eee2b-f4b9-4cbd-a819-c4539a309409"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomForestRegressor(random_state=2023)"
            ],
            "text/html": [
              "<style>#sk-container-id-5 {color: black;background-color: white;}#sk-container-id-5 pre{padding: 0;}#sk-container-id-5 div.sk-toggleable {background-color: white;}#sk-container-id-5 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-5 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-5 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-5 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-5 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-5 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-5 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-5 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-5 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-5 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-5 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-5 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-5 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-5 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-5 div.sk-item {position: relative;z-index: 1;}#sk-container-id-5 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-5 div.sk-item::before, #sk-container-id-5 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-5 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-5 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-5 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-5 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-5 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-5 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-5 div.sk-label-container {text-align: center;}#sk-container-id-5 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-5 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-5\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestRegressor(random_state=2023)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" checked><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestRegressor</label><div class=\"sk-toggleable__content\"><pre>RandomForestRegressor(random_state=2023)</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 모델을 사용하여 테스트 데이터 예측\n",
        "\n",
        "y_pred = model.predict(x_val)"
      ],
      "metadata": {
        "id": "VyelV4DDPLJl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import sklearn.metrics\n",
        "\n",
        "print(sklearn.metrics.__all__)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5X0Y9_mlPx4z",
        "outputId": "f1dd8f1e-447f-4a61-ea0b-e2ff08f0e237"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['accuracy_score', 'adjusted_mutual_info_score', 'adjusted_rand_score', 'auc', 'average_precision_score', 'balanced_accuracy_score', 'calinski_harabasz_score', 'check_scoring', 'class_likelihood_ratios', 'classification_report', 'cluster', 'cohen_kappa_score', 'completeness_score', 'ConfusionMatrixDisplay', 'confusion_matrix', 'consensus_score', 'coverage_error', 'd2_tweedie_score', 'd2_absolute_error_score', 'd2_pinball_score', 'dcg_score', 'davies_bouldin_score', 'DetCurveDisplay', 'det_curve', 'DistanceMetric', 'euclidean_distances', 'explained_variance_score', 'f1_score', 'fbeta_score', 'fowlkes_mallows_score', 'get_scorer', 'hamming_loss', 'hinge_loss', 'homogeneity_completeness_v_measure', 'homogeneity_score', 'jaccard_score', 'label_ranking_average_precision_score', 'label_ranking_loss', 'log_loss', 'make_scorer', 'nan_euclidean_distances', 'matthews_corrcoef', 'max_error', 'mean_absolute_error', 'mean_squared_error', 'mean_squared_log_error', 'mean_pinball_loss', 'mean_poisson_deviance', 'mean_gamma_deviance', 'mean_tweedie_deviance', 'median_absolute_error', 'mean_absolute_percentage_error', 'multilabel_confusion_matrix', 'mutual_info_score', 'ndcg_score', 'normalized_mutual_info_score', 'pair_confusion_matrix', 'pairwise_distances', 'pairwise_distances_argmin', 'pairwise_distances_argmin_min', 'pairwise_distances_chunked', 'pairwise_kernels', 'PrecisionRecallDisplay', 'precision_recall_curve', 'precision_recall_fscore_support', 'precision_score', 'PredictionErrorDisplay', 'r2_score', 'rand_score', 'recall_score', 'RocCurveDisplay', 'roc_auc_score', 'roc_curve', 'SCORERS', 'get_scorer_names', 'silhouette_samples', 'silhouette_score', 'top_k_accuracy_score', 'v_measure_score', 'zero_one_loss', 'brier_score_loss']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 모델 성능 평가 (회귀모델을 사용하여 Rsq, MSE 값을 산출)\n",
        "\n",
        "from sklearn.metrics import r2_score, mean_squared_error\n",
        "mse = mean_squared_error(y_val, y_pred) # 실제값, 예측값\n",
        "r2 = r2_score(y_val, y_pred)"
      ],
      "metadata": {
        "id": "oipCJv2UPLBY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(mse)\n",
        "print(r2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2D_Hon1FQZ-K",
        "outputId": "2cdb3b76-ce1c-48bd-d3ea-7283a7ad99a9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2563.5036816901406\n",
            "0.5250663004710372\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# RMSE\n",
        "rmse = mse**0.5\n",
        "print(rmse)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iN-wS50aQSnY",
        "outputId": "e6e63c7b-e937-41af-d14e-ec5281bc72d5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "50.631054518843875\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5) 예측값 제출\n",
        "(주의) x_test 를 모델에 넣어 나온 예측값을 제출해야함"
      ],
      "metadata": {
        "id": "D4JSiFC0RDsD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# (실기시험 안내사항)\n",
        "# 아래 코드 예측변수와 수험번호를 개인별로 변경하여 활용\n",
        "# pd.DataFrame({'cust_id': cust_id, 'target': y_result}).to_csv('003000000.csv', index=False)\n",
        "# 모델을 사용하여 테스트 데이터 예측\n",
        "y_result = model.predict(x_test)\n",
        "result = pd.DataFrame({'cust_id': cust_id, 'target': y_result})\n",
        "print(result[:5])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ybxZeiJmRHvC",
        "outputId": "2e932059-58ab-48f3-8a8c-9078628a81a0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   cust_id  target\n",
            "0      280  186.51\n",
            "1      412  255.92\n",
            "2       68   77.97\n",
            "3      324  185.64\n",
            "4      101  111.14\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 제2유형_연습하기_팁 예측하기(회귀)\n",
        "✅ 데이터 분석 순서\n",
        "1. 라이브러리 및 데이터 확인\n",
        "2. 데이터 탐색(EDA)\n",
        "3. 데이터 전처리 및 분리\n",
        "4. 모델링 및 성능평가\n",
        "5. 예측값 제출"
      ],
      "metadata": {
        "id": "CU79DTO_RPzv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1) 라이브러리 및 데이터 확인"
      ],
      "metadata": {
        "id": "miMXuKd-9pPL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "9mh2cWyO9nKy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 실기 시험 데이터셋으로 셋팅하기 (수정금지)\n",
        "import seaborn as sns\n",
        "# tips 데이터셋 로드\n",
        "df = sns.load_dataset('tips')\n",
        "x = df.drop(['tip'], axis=1)\n",
        "y = df['tip']\n",
        "# 실기 시험 데이터셋으로 셋팅하기 (수정금지)\n",
        "from sklearn.model_selection import train_test_split\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=2023)\n",
        "x_test = pd.DataFrame(x_test.reset_index())\n",
        "x_train = pd.DataFrame(x_train.reset_index())\n",
        "y_train = pd.DataFrame(y_train.reset_index())\n",
        "x_test.rename(columns={'index':'cust_id'}, inplace=True)\n",
        "x_train.rename(columns={'index':'cust_id'}, inplace=True)\n",
        "y_train.columns = ['cust_id', 'target']"
      ],
      "metadata": {
        "id": "9H6HXT6a9nH9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "레스토랑의 tip 예측 문제\n",
        "- 데이터의 결측치, 이상치, 변수에 대해 처리하고\n",
        "- 회귀모델을 사용하여 Rsq, MSE 값을 산출하시오.<br>\n",
        "\n",
        "데이터셋 설명\n",
        "- total_bill(총 청구액): 손님의 식사 총 청구액\n",
        "- tip(팁): 팁의 양\n",
        "- sex(성별): 손님의 성별\n",
        "- smoker(흡연자): 손님의 흡연 여부(\"Yes\" 또는 \"No\")\n",
        "- day(요일): 식사가 이루어진 요일\n",
        "- time(시간): 점심 또는 저녁 중 언제 식사가 이루어졌는지\n",
        "- size(인원 수): 식사에 참석한 인원 수"
      ],
      "metadata": {
        "id": "psmgHVjh9x_e"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2) 데이터 탐색 (EDA)"
      ],
      "metadata": {
        "id": "GB0diEpv-A2W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 데이터 행/열 확인\n",
        "print(x_train.shape)\n",
        "print(x_test.shape)\n",
        "print(y_train.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bP3_1kEg9m-W",
        "outputId": "f6de5f66-7eb3-498d-929e-12fe2f15962e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(195, 7)\n",
            "(49, 7)\n",
            "(195, 2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 초기 데이터 확인\n",
        "\n",
        "print(x_train.head())\n",
        "print(x_test.head())\n",
        "print(y_train.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WaF3FtLt9m8N",
        "outputId": "aeaa2b58-3c37-4739-ec6e-277bd790eda2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   cust_id  total_bill     sex smoker  day    time  size\n",
            "0      158       13.39  Female     No  Sun  Dinner     2\n",
            "1      186       20.90  Female    Yes  Sun  Dinner     3\n",
            "2       21       20.29  Female     No  Sat  Dinner     2\n",
            "3       74       14.73  Female     No  Sat  Dinner     2\n",
            "4       43        9.68    Male     No  Sun  Dinner     2\n",
            "   cust_id  total_bill     sex smoker  day    time  size\n",
            "0      154       19.77    Male     No  Sun  Dinner     4\n",
            "1        4       24.59  Female     No  Sun  Dinner     4\n",
            "2       30        9.55    Male     No  Sat  Dinner     2\n",
            "3       75       10.51    Male     No  Sat  Dinner     2\n",
            "4       33       20.69  Female     No  Sat  Dinner     4\n",
            "   cust_id  target\n",
            "0      158    2.61\n",
            "1      186    3.50\n",
            "2       21    2.75\n",
            "3       74    2.20\n",
            "4       43    1.32\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 변수명과 데이터 타입이 매칭 되는지, 결측치가 있는지 확인\n",
        "\n",
        "print(x_train.info())\n",
        "print(x_test.info())\n",
        "print(y_train.info())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CIEZFil7-UA9",
        "outputId": "ccc2a4ed-57c9-4486-af55-1fa7d87cb740"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 195 entries, 0 to 194\n",
            "Data columns (total 7 columns):\n",
            " #   Column      Non-Null Count  Dtype   \n",
            "---  ------      --------------  -----   \n",
            " 0   cust_id     195 non-null    int64   \n",
            " 1   total_bill  195 non-null    float64 \n",
            " 2   sex         195 non-null    category\n",
            " 3   smoker      195 non-null    category\n",
            " 4   day         195 non-null    category\n",
            " 5   time        195 non-null    category\n",
            " 6   size        195 non-null    int64   \n",
            "dtypes: category(4), float64(1), int64(2)\n",
            "memory usage: 6.0 KB\n",
            "None\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 49 entries, 0 to 48\n",
            "Data columns (total 7 columns):\n",
            " #   Column      Non-Null Count  Dtype   \n",
            "---  ------      --------------  -----   \n",
            " 0   cust_id     49 non-null     int64   \n",
            " 1   total_bill  49 non-null     float64 \n",
            " 2   sex         49 non-null     category\n",
            " 3   smoker      49 non-null     category\n",
            " 4   day         49 non-null     category\n",
            " 5   time        49 non-null     category\n",
            " 6   size        49 non-null     int64   \n",
            "dtypes: category(4), float64(1), int64(2)\n",
            "memory usage: 2.0 KB\n",
            "None\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 195 entries, 0 to 194\n",
            "Data columns (total 2 columns):\n",
            " #   Column   Non-Null Count  Dtype  \n",
            "---  ------   --------------  -----  \n",
            " 0   cust_id  195 non-null    int64  \n",
            " 1   target   195 non-null    float64\n",
            "dtypes: float64(1), int64(1)\n",
            "memory usage: 3.2 KB\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# object, category 데이터도 추가 확인\n",
        "\n",
        "print(x_train.describe(include='category'))\n",
        "print(x_test.describe(include='category'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aw6qSmLq-gto",
        "outputId": "96641b8f-f4de-4d2e-dbf6-1ebaead46534"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "         sex smoker  day    time\n",
            "count    195    195  195     195\n",
            "unique     2      2    4       2\n",
            "top     Male     No  Sat  Dinner\n",
            "freq     125    120   71     142\n",
            "         sex smoker  day    time\n",
            "count     49     49   49      49\n",
            "unique     2      2    4       2\n",
            "top     Male     No  Sat  Dinner\n",
            "freq      32     31   16      34\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# y데이터 구체적으로 확인\n",
        "print(y_train.head())\n",
        "print(y_train.describe())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nWKbrUHr-ztL",
        "outputId": "28862388-bccd-4c19-9266-8504ba326e7b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   cust_id  target\n",
            "0      158    2.61\n",
            "1      186    3.50\n",
            "2       21    2.75\n",
            "3       74    2.20\n",
            "4       43    1.32\n",
            "          cust_id      target\n",
            "count  195.000000  195.000000\n",
            "mean   122.056410    3.021692\n",
            "std     70.668034    1.402690\n",
            "min      0.000000    1.000000\n",
            "25%     59.500000    2.000000\n",
            "50%    121.000000    2.920000\n",
            "75%    182.500000    3.530000\n",
            "max    243.000000   10.000000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3) 데이터 전처리 및 분리"
      ],
      "metadata": {
        "id": "X923EurE-8My"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 결측치 확인\n",
        "\n",
        "print(x_train.isnull().sum())\n",
        "print(x_test.isnull().sum())\n",
        "print(y_train.isnull().sum())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DN4ItO-q--z6",
        "outputId": "12605dc1-9bcf-45d5-c53c-cceec91f2b55"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cust_id       0\n",
            "total_bill    0\n",
            "sex           0\n",
            "smoker        0\n",
            "day           0\n",
            "time          0\n",
            "size          0\n",
            "dtype: int64\n",
            "cust_id       0\n",
            "total_bill    0\n",
            "sex           0\n",
            "smoker        0\n",
            "day           0\n",
            "time          0\n",
            "size          0\n",
            "dtype: int64\n",
            "cust_id    0\n",
            "target     0\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 변수처리\n",
        "\n",
        "cust_id = x_test['cust_id'].copy()\n",
        "\n",
        "x_train = x_train.drop(columns = ['cust_id'])\n",
        "x_test = x_test.drop(columns = ['cust_id'])"
      ],
      "metadata": {
        "id": "pz3p9HHy_RQS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(dir(pd))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DlsCpIKWA7K9",
        "outputId": "307ed0b3-af57-4428-b8ae-2cbb9385c0f2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['ArrowDtype', 'BooleanDtype', 'Categorical', 'CategoricalDtype', 'CategoricalIndex', 'DataFrame', 'DateOffset', 'DatetimeIndex', 'DatetimeTZDtype', 'ExcelFile', 'ExcelWriter', 'Flags', 'Float32Dtype', 'Float64Dtype', 'Float64Index', 'Grouper', 'HDFStore', 'Index', 'IndexSlice', 'Int16Dtype', 'Int32Dtype', 'Int64Dtype', 'Int64Index', 'Int8Dtype', 'Interval', 'IntervalDtype', 'IntervalIndex', 'MultiIndex', 'NA', 'NaT', 'NamedAgg', 'Period', 'PeriodDtype', 'PeriodIndex', 'RangeIndex', 'Series', 'SparseDtype', 'StringDtype', 'Timedelta', 'TimedeltaIndex', 'Timestamp', 'UInt16Dtype', 'UInt32Dtype', 'UInt64Dtype', 'UInt64Index', 'UInt8Dtype', '__all__', '__builtins__', '__cached__', '__deprecated_num_index_names', '__dir__', '__doc__', '__docformat__', '__file__', '__getattr__', '__git_version__', '__loader__', '__name__', '__package__', '__path__', '__spec__', '__version__', '_config', '_is_numpy_dev', '_libs', '_testing', '_typing', '_version', 'annotations', 'api', 'array', 'arrays', 'bdate_range', 'compat', 'concat', 'core', 'crosstab', 'cut', 'date_range', 'describe_option', 'errors', 'eval', 'factorize', 'from_dummies', 'get_dummies', 'get_option', 'infer_freq', 'interval_range', 'io', 'isna', 'isnull', 'json_normalize', 'lreshape', 'melt', 'merge', 'merge_asof', 'merge_ordered', 'notna', 'notnull', 'offsets', 'option_context', 'options', 'pandas', 'period_range', 'pivot', 'pivot_table', 'plotting', 'qcut', 'read_clipboard', 'read_csv', 'read_excel', 'read_feather', 'read_fwf', 'read_gbq', 'read_hdf', 'read_html', 'read_json', 'read_orc', 'read_parquet', 'read_pickle', 'read_sas', 'read_spss', 'read_sql', 'read_sql_query', 'read_sql_table', 'read_stata', 'read_table', 'read_xml', 'reset_option', 'set_eng_float_format', 'set_option', 'show_versions', 'test', 'testing', 'timedelta_range', 'to_datetime', 'to_numeric', 'to_pickle', 'to_timedelta', 'tseries', 'unique', 'util', 'value_counts', 'wide_to_long']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(dir(pd.DataFrame))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4IbxgTwUAUbr",
        "outputId": "cce90f57-87aa-4786-c77f-ed4309505b8a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['T', '_AXIS_LEN', '_AXIS_NAMES', '_AXIS_NUMBERS', '_AXIS_ORDERS', '_AXIS_TO_AXIS_NUMBER', '_HANDLED_TYPES', '__abs__', '__add__', '__and__', '__annotations__', '__array__', '__array_priority__', '__array_ufunc__', '__array_wrap__', '__bool__', '__class__', '__contains__', '__copy__', '__dataframe__', '__deepcopy__', '__delattr__', '__delitem__', '__dict__', '__dir__', '__divmod__', '__doc__', '__eq__', '__finalize__', '__floordiv__', '__format__', '__ge__', '__getattr__', '__getattribute__', '__getitem__', '__getstate__', '__gt__', '__hash__', '__iadd__', '__iand__', '__ifloordiv__', '__imod__', '__imul__', '__init__', '__init_subclass__', '__invert__', '__ior__', '__ipow__', '__isub__', '__iter__', '__itruediv__', '__ixor__', '__le__', '__len__', '__lt__', '__matmul__', '__mod__', '__module__', '__mul__', '__ne__', '__neg__', '__new__', '__nonzero__', '__or__', '__pos__', '__pow__', '__radd__', '__rand__', '__rdivmod__', '__reduce__', '__reduce_ex__', '__repr__', '__rfloordiv__', '__rmatmul__', '__rmod__', '__rmul__', '__ror__', '__round__', '__rpow__', '__rsub__', '__rtruediv__', '__rxor__', '__setattr__', '__setitem__', '__setstate__', '__sizeof__', '__str__', '__sub__', '__subclasshook__', '__truediv__', '__weakref__', '__xor__', '_accessors', '_accum_func', '_add_numeric_operations', '_agg_by_level', '_agg_examples_doc', '_agg_summary_and_see_also_doc', '_align_frame', '_align_series', '_append', '_arith_method', '_as_manager', '_box_col_values', '_can_fast_transpose', '_check_inplace_and_allows_duplicate_labels', '_check_inplace_setting', '_check_is_chained_assignment_possible', '_check_label_or_level_ambiguity', '_check_setitem_copy', '_clear_item_cache', '_clip_with_one_bound', '_clip_with_scalar', '_cmp_method', '_combine_frame', '_consolidate', '_consolidate_inplace', '_construct_axes_dict', '_construct_axes_from_arguments', '_construct_result', '_constructor', '_constructor_sliced', '_convert', '_count_level', '_data', '_dir_additions', '_dir_deletions', '_dispatch_frame_op', '_drop_axis', '_drop_labels_or_levels', '_ensure_valid_index', '_find_valid_index', '_from_arrays', '_get_agg_axis', '_get_axis', '_get_axis_name', '_get_axis_number', '_get_axis_resolvers', '_get_block_manager_axis', '_get_bool_data', '_get_cleaned_column_resolvers', '_get_column_array', '_get_index_resolvers', '_get_item_cache', '_get_label_or_level_values', '_get_numeric_data', '_get_value', '_getitem_bool_array', '_getitem_multilevel', '_gotitem', '_hidden_attrs', '_indexed_same', '_info_axis', '_info_axis_name', '_info_axis_number', '_info_repr', '_init_mgr', '_inplace_method', '_internal_names', '_internal_names_set', '_is_copy', '_is_homogeneous_type', '_is_label_or_level_reference', '_is_label_reference', '_is_level_reference', '_is_mixed_type', '_is_view', '_iset_item', '_iset_item_mgr', '_iset_not_inplace', '_iter_column_arrays', '_ixs', '_join_compat', '_logical_func', '_logical_method', '_maybe_cache_changed', '_maybe_update_cacher', '_metadata', '_min_count_stat_function', '_needs_reindex_multi', '_protect_consolidate', '_reduce', '_reduce_axis1', '_reindex_axes', '_reindex_columns', '_reindex_index', '_reindex_multi', '_reindex_with_indexers', '_rename', '_replace_columnwise', '_repr_data_resource_', '_repr_fits_horizontal_', '_repr_fits_vertical_', '_repr_html_', '_repr_latex_', '_reset_cache', '_reset_cacher', '_sanitize_column', '_series', '_set_axis', '_set_axis_name', '_set_axis_nocheck', '_set_is_copy', '_set_item', '_set_item_frame_value', '_set_item_mgr', '_set_value', '_setitem_array', '_setitem_frame', '_setitem_slice', '_slice', '_stat_axis', '_stat_axis_name', '_stat_axis_number', '_stat_function', '_stat_function_ddof', '_take', '_take_with_is_copy', '_to_dict_of_blocks', '_typ', '_update_inplace', '_validate_dtype', '_values', '_where', 'abs', 'add', 'add_prefix', 'add_suffix', 'agg', 'aggregate', 'align', 'all', 'any', 'append', 'apply', 'applymap', 'asfreq', 'asof', 'assign', 'astype', 'at', 'at_time', 'attrs', 'axes', 'backfill', 'between_time', 'bfill', 'bool', 'boxplot', 'clip', 'columns', 'combine', 'combine_first', 'compare', 'convert_dtypes', 'copy', 'corr', 'corrwith', 'count', 'cov', 'cummax', 'cummin', 'cumprod', 'cumsum', 'describe', 'diff', 'div', 'divide', 'dot', 'drop', 'drop_duplicates', 'droplevel', 'dropna', 'dtypes', 'duplicated', 'empty', 'eq', 'equals', 'eval', 'ewm', 'expanding', 'explode', 'ffill', 'fillna', 'filter', 'first', 'first_valid_index', 'flags', 'floordiv', 'from_dict', 'from_records', 'ge', 'get', 'groupby', 'gt', 'head', 'hist', 'iat', 'idxmax', 'idxmin', 'iloc', 'index', 'infer_objects', 'info', 'insert', 'interpolate', 'isetitem', 'isin', 'isna', 'isnull', 'items', 'iteritems', 'iterrows', 'itertuples', 'join', 'keys', 'kurt', 'kurtosis', 'last', 'last_valid_index', 'le', 'loc', 'lookup', 'lt', 'mad', 'mask', 'max', 'mean', 'median', 'melt', 'memory_usage', 'merge', 'min', 'mod', 'mode', 'mul', 'multiply', 'ndim', 'ne', 'nlargest', 'notna', 'notnull', 'nsmallest', 'nunique', 'pad', 'pct_change', 'pipe', 'pivot', 'pivot_table', 'plot', 'pop', 'pow', 'prod', 'product', 'quantile', 'query', 'radd', 'rank', 'rdiv', 'reindex', 'reindex_like', 'rename', 'rename_axis', 'reorder_levels', 'replace', 'resample', 'reset_index', 'rfloordiv', 'rmod', 'rmul', 'rolling', 'round', 'rpow', 'rsub', 'rtruediv', 'sample', 'select_dtypes', 'sem', 'set_axis', 'set_flags', 'set_index', 'shape', 'shift', 'size', 'skew', 'slice_shift', 'sort_index', 'sort_values', 'sparse', 'squeeze', 'stack', 'std', 'style', 'sub', 'subtract', 'sum', 'swapaxes', 'swaplevel', 'tail', 'take', 'to_clipboard', 'to_csv', 'to_dict', 'to_excel', 'to_feather', 'to_gbq', 'to_hdf', 'to_html', 'to_json', 'to_latex', 'to_markdown', 'to_numpy', 'to_orc', 'to_parquet', 'to_period', 'to_pickle', 'to_records', 'to_sql', 'to_stata', 'to_string', 'to_timestamp', 'to_xarray', 'to_xml', 'transform', 'transpose', 'truediv', 'truncate', 'tshift', 'tz_convert', 'tz_localize', 'unstack', 'update', 'value_counts', 'values', 'var', 'where', 'xs']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 변수처리(원핫인코딩) , 카테고리 타입\n",
        "\n",
        "# get_dummies 가 생각이 안난다면 print(dir(pd))\n",
        "x_train = pd.get_dummies(x_train)\n",
        "x_test = pd.get_dummies(x_test)\n",
        "\n",
        "print(x_train.info())\n",
        "print(x_test.info())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gARhS6uEAIFS",
        "outputId": "7ca76020-a9ff-4105-d2a5-60b2160284d9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 195 entries, 0 to 194\n",
            "Data columns (total 12 columns):\n",
            " #   Column       Non-Null Count  Dtype  \n",
            "---  ------       --------------  -----  \n",
            " 0   total_bill   195 non-null    float64\n",
            " 1   size         195 non-null    int64  \n",
            " 2   sex_Male     195 non-null    uint8  \n",
            " 3   sex_Female   195 non-null    uint8  \n",
            " 4   smoker_Yes   195 non-null    uint8  \n",
            " 5   smoker_No    195 non-null    uint8  \n",
            " 6   day_Thur     195 non-null    uint8  \n",
            " 7   day_Fri      195 non-null    uint8  \n",
            " 8   day_Sat      195 non-null    uint8  \n",
            " 9   day_Sun      195 non-null    uint8  \n",
            " 10  time_Lunch   195 non-null    uint8  \n",
            " 11  time_Dinner  195 non-null    uint8  \n",
            "dtypes: float64(1), int64(1), uint8(10)\n",
            "memory usage: 5.1 KB\n",
            "None\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 49 entries, 0 to 48\n",
            "Data columns (total 12 columns):\n",
            " #   Column       Non-Null Count  Dtype  \n",
            "---  ------       --------------  -----  \n",
            " 0   total_bill   49 non-null     float64\n",
            " 1   size         49 non-null     int64  \n",
            " 2   sex_Male     49 non-null     uint8  \n",
            " 3   sex_Female   49 non-null     uint8  \n",
            " 4   smoker_Yes   49 non-null     uint8  \n",
            " 5   smoker_No    49 non-null     uint8  \n",
            " 6   day_Thur     49 non-null     uint8  \n",
            " 7   day_Fri      49 non-null     uint8  \n",
            " 8   day_Sat      49 non-null     uint8  \n",
            " 9   day_Sun      49 non-null     uint8  \n",
            " 10  time_Lunch   49 non-null     uint8  \n",
            " 11  time_Dinner  49 non-null     uint8  \n",
            "dtypes: float64(1), int64(1), uint8(10)\n",
            "memory usage: 1.4 KB\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 데이터 분리\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train['target'], test_size=0.2, random_state=23)\n",
        "\n",
        "print(x_train.shape)\n",
        "print(x_val.shape)\n",
        "print(y_train.shape)\n",
        "print(y_val.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fxW2AZ27Bm9J",
        "outputId": "25ac34e1-d584-4e64-8d64-0722f60cab38"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(156, 12)\n",
            "(39, 12)\n",
            "(156,)\n",
            "(39,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4) 모델링 및 성능평가"
      ],
      "metadata": {
        "id": "cVu1ySauCEQ2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 랜덤포레스트 모델 사용\n",
        "\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "model = RandomForestRegressor()\n",
        "model.fit(x_train, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 75
        },
        "id": "e9EFc_PDCGlt",
        "outputId": "d527e75a-4a67-4f60-fefa-a6988960ba5d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomForestRegressor()"
            ],
            "text/html": [
              "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestRegressor()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestRegressor</label><div class=\"sk-toggleable__content\"><pre>RandomForestRegressor()</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sklearn\n",
        "print(sklearn.metrics.__all__)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cI9fDxQUNd-5",
        "outputId": "774050ee-5c81-4ae6-cf6b-f93ea7511495"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['accuracy_score', 'adjusted_mutual_info_score', 'adjusted_rand_score', 'auc', 'average_precision_score', 'balanced_accuracy_score', 'calinski_harabasz_score', 'check_scoring', 'class_likelihood_ratios', 'classification_report', 'cluster', 'cohen_kappa_score', 'completeness_score', 'ConfusionMatrixDisplay', 'confusion_matrix', 'consensus_score', 'coverage_error', 'd2_tweedie_score', 'd2_absolute_error_score', 'd2_pinball_score', 'dcg_score', 'davies_bouldin_score', 'DetCurveDisplay', 'det_curve', 'DistanceMetric', 'euclidean_distances', 'explained_variance_score', 'f1_score', 'fbeta_score', 'fowlkes_mallows_score', 'get_scorer', 'hamming_loss', 'hinge_loss', 'homogeneity_completeness_v_measure', 'homogeneity_score', 'jaccard_score', 'label_ranking_average_precision_score', 'label_ranking_loss', 'log_loss', 'make_scorer', 'nan_euclidean_distances', 'matthews_corrcoef', 'max_error', 'mean_absolute_error', 'mean_squared_error', 'mean_squared_log_error', 'mean_pinball_loss', 'mean_poisson_deviance', 'mean_gamma_deviance', 'mean_tweedie_deviance', 'median_absolute_error', 'mean_absolute_percentage_error', 'multilabel_confusion_matrix', 'mutual_info_score', 'ndcg_score', 'normalized_mutual_info_score', 'pair_confusion_matrix', 'pairwise_distances', 'pairwise_distances_argmin', 'pairwise_distances_argmin_min', 'pairwise_distances_chunked', 'pairwise_kernels', 'PrecisionRecallDisplay', 'precision_recall_curve', 'precision_recall_fscore_support', 'precision_score', 'PredictionErrorDisplay', 'r2_score', 'rand_score', 'recall_score', 'RocCurveDisplay', 'roc_auc_score', 'roc_curve', 'SCORERS', 'get_scorer_names', 'silhouette_samples', 'silhouette_score', 'top_k_accuracy_score', 'v_measure_score', 'zero_one_loss', 'brier_score_loss']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 예측\n",
        "\n",
        "y_pred = model.predict(x_val)"
      ],
      "metadata": {
        "id": "4FPWUiFQNwRs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 성능평가 (Rsq, MSE 값을 산출)\n",
        "\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "\n",
        "mse = mean_squared_error(y_val, y_pred)\n",
        "r2 = r2_score(y_val, y_pred)\n",
        "\n",
        "print(mse)\n",
        "print(r2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TPK3NJGJNQWB",
        "outputId": "266eda7d-2c15-40f7-d9c2-67532e481159"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.9858462474358967\n",
            "0.42596048898202676\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# RMSE\n",
        "rmse = mse**0.5\n",
        "print(rmse)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sAmvA1iqNQTl",
        "outputId": "24d2a6b2-2296-49dd-c85f-e06b5eb3b8af"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.9928979038329654\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5) 예측값 제출\n",
        "\n",
        "(주의) x_test 를 모델에 넣어 나온 예측값을 제출해야함"
      ],
      "metadata": {
        "id": "_tHPskY5OQTY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 모델을 사용하여 테스트 데이터 예측\n",
        "\n",
        "y_result = model.predict(x_test)\n",
        "result = pd.DataFrame({'cust_id' : cust_id, 'target' : y_result}).to_csv('_.csv', index=False)\n",
        "df2 = pd.read_csv('_.csv')\n",
        "print(df2.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UaB-3zD3NQQ-",
        "outputId": "b09c0b2f-80fd-4e8e-a3e1-27a1dd91bb23"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   cust_id  target\n",
            "0      154  3.5308\n",
            "1        4  4.1042\n",
            "2       30  1.7843\n",
            "3       75  1.8059\n",
            "4       33  3.1430\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 구름 2유형 백화점 성별예측"
      ],
      "metadata": {
        "id": "cxnR-RGOmIS9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 데이터 파일 읽기 예제\n",
        "import pandas as pd\n",
        "train = pd.read_csv(\"data/customer_train.csv\")\n",
        "test = pd.read_csv(\"data/customer_test.csv\")\n",
        "\n",
        "y_train = train[[\"성별\"]]\n",
        "x_train = train.drop(columns = [\"성별\"], axis=1)\n",
        "x_test = test\n",
        "\n",
        "x_train['환불금액'].fillna(0, inplace = True)\n",
        "x_test['환불금액'].fillna(0, inplace = True)\n",
        "\n",
        "#  범주형 데이터 수치화\n",
        "import sklearn.preprocessing\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "cols=['주구매상품', '주구매지점'] # 범주형 데이터\n",
        "for col in cols:\n",
        "\tle = LabelEncoder()\n",
        "\tx_train[col]=le.fit_transform(x_train[col])\n",
        "\tx_test[col]=le.transform(x_test[col])\n",
        "# print(x_train.head(5))\n",
        "\n",
        "import sklearn.model_selection\n",
        "from sklearn.model_selection import train_test_split\n",
        "x_tr, x_val, y_tr, y_val = train_test_split(x_train, y_train, test_size=0.2, stratify = y_train, random_state=2023)\n",
        "\n",
        "# print(x_tr.shape)\n",
        "# print(x_val.shape)\n",
        "# print(y_tr.shape)\n",
        "# print(y_val.shape)\n",
        "\n",
        "import sklearn.ensemble\n",
        "\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "model = RandomForestClassifier(n_estimators=100, max_leaf_nodes=128)\n",
        "model.fit(x_tr, y_tr.values.ravel())\n",
        "\n",
        "y_pred = model.predict(x_val)\n",
        "\n",
        "import sklearn.metrics\n",
        "from sklearn.metrics import accuracy_score, f1_score, recall_score, precision_score\n",
        "acc = accuracy_score(y_val, y_pred) # (실제값, 예측값)\n",
        "f1 = f1_score(y_val, y_pred, average='macro')\n",
        "\n",
        "print(acc)\n",
        "\n",
        "pd.DataFrame(y_pred, columns=['pred']).to_csv('result.csv', index=False)\n",
        "\n",
        "# 답안 제출 참고\n",
        "# 아래 코드 예측변수 등은 개인별로 변경하여 활용\n",
        "# pd.DataFrame변수.to_csv('result.csv', index=False)\n",
        "df2 = pd.read_csv('result.csv')\n",
        "print(df2.head())\n"
      ],
      "metadata": {
        "id": "CjOXEeaQmH96",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 428
        },
        "outputId": "41247c02-30a2-4ab8-bfde-627f089ddfac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-49-874c1658f368>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# 데이터 파일 읽기 예제\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mtrain\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"data/customer_train.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mtest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"data/customer_test.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    209\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m                     \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnew_arg_name\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_arg_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 211\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    329\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfind_stack_level\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m                 )\n\u001b[0;32m--> 331\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    332\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m         \u001b[0;31m# error: \"Callable[[VarArg(Any), KwArg(Any)], Any]\" has no\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    948\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 950\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    951\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    952\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    603\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    604\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 605\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    606\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    607\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1440\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1442\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1443\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1444\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1733\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1734\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1735\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1736\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1737\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    854\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    855\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 856\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    857\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    858\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'data/customer_train.csv'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 출력을 원하실 경우 print() 함수 활용\n",
        "# 예시) print(df.head())\n",
        "\n",
        "# getcwd(), chdir() 등 작업 폴더 설정 불필요\n",
        "# 파일 경로 상 내부 드라이브 경로(C: 등) 접근 불가\n",
        "\n",
        "import pandas as pd\n",
        "import sklearn\n",
        "\n",
        "train = pd.read_csv(\"data/customer_train.csv\")\n",
        "test = pd.read_csv(\"data/customer_test.csv\")\n",
        "train = train.drop(columns = ['회원ID'], axis = 1)\n",
        "test = test.drop(columns = ['회원ID'], axis = 1)\n",
        "\n",
        "# EDA #\n",
        "# print(train.shape) #(3500, 11)\n",
        "# print(test.shape) # (2482, 10)\n",
        "\n",
        "# print(train.info()) # 환불금액 결측치는 0으로\n",
        "# print(test.info()) # 환불금액 결측치는 0으로\n",
        "\n",
        "# print(train.describe(include = 'O'))\n",
        "# print(test.describe(include = 'O'))\n",
        "\n",
        "## 데이터 전처리 / 분리 ##\n",
        "\n",
        "# x_train과 y_train, x_test를 별도로 할당\n",
        "y_train = train['성별']\n",
        "x_train = train.drop(columns = '성별', axis = 1)\n",
        "x_test = test\n",
        "\n",
        "# 결측치 저리\n",
        "x_train['환불금액'].fillna(0, inplace=True)\n",
        "x_test['환불금액'].fillna(0, inplace=True)\n",
        "\n",
        "# 범주형 데이터 수치화 -> 라벨인코더\n",
        "import sklearn.preprocessing\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "cols = ['주구매상품', '주구매지점']\n",
        "for col in cols:\n",
        "\tle = LabelEncoder()\n",
        "\tx_train[col] = le.fit_transform(x_train[col])\n",
        "\tx_test[col] = le.transform(x_test[col])\n",
        "\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size = 0.2, stratify = y_train, random_state = 2023)\n",
        "\n",
        "## 모델링 / 성능평가 ##\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "model = RandomForestClassifier()\n",
        "model.fit(x_train, y_train)\n",
        "\n",
        "# 모델에 적용\n",
        "y_pred = model.predict(x_val)\n",
        "\n",
        "# 성능평가 (ROC_AUC 평가지표에 따라 평가)\n",
        "# print(sklearn.metrics.__all__)\n",
        "from sklearn.metrics import accuracy_score, f1_score, recall_score, roc_auc_score, precision_score\n",
        "acc = accuracy_score(y_val, y_pred)\n",
        "f1 = f1_score(y_val, y_pred, average = 'macro')\n",
        "print(acc)\n",
        "print(f1)\n",
        "\n",
        "\n",
        "## 예측값 제출 ##\n",
        "pd.DataFrame(y_pred, columns=['pred']).to_csv(\"result.csv\", index=False)\n",
        "\n",
        "df2 = pd.read_csv('result.csv')\n",
        "print(df2.head())\n",
        "\n",
        "\n",
        "# 답안 제출 참고\n",
        "# 아래 코드는 예시이며 변수명 등 개인별로 변경하여 활용\n",
        "# pd.DataFrame변수.to_csv(\"result.csv\", index=False)\n"
      ],
      "metadata": {
        "id": "dfCDCue5S1w3"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}